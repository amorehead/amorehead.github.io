<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="3MAO3jcAYPrqCbe8CI7asi-37aEVhl_nC6GX9habT9o"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Alex C. Morehead </title> <meta name="author" content="Alex C. Morehead"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://amorehead.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Alex</span> C. Morehead </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/books/">bookshelf</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> * denotes equal contribution <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/gRNAde-480.webp 480w,/assets/img/publication_preview/gRNAde-800.webp 800w,/assets/img/publication_preview/gRNAde-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/gRNAde.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="gRNAde.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="joshi2025grnade" class="col-sm-8"> <div class="title">gRNAde: Geometric Deep Learning for 3D RNA inverse design</div> <div class="author"> Chaitanya K Joshi, Arian R Jamasb, Ramon Viñas, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Charles Harris, Simon V Mathis, Alex Morehead, Rishabh Anand, Pietro Liò' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In The Thirteenth International Conference on Learning Representations (ICLR)</em>, 2025 </div> <div class="periodical"> Multi-state geometric RNA sequence design designated as an ICLR spotlight </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=lvw3UgeVxS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:dhFuZR0502QC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ISMB</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/FlowDock-480.webp 480w,/assets/img/publication_preview/FlowDock-800.webp 800w,/assets/img/publication_preview/FlowDock-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/FlowDock.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="FlowDock.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025flowdock" class="col-sm-8"> <div class="title">FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction</div> <div class="author"> <em>Alex Morehead</em>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In Intelligent Systems for Molecular Biology (ISMB)</em>, 2025 </div> <div class="periodical"> First all-atom flow matching model for protein-ligand docking, presented as a CASP16 top-5 method </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article/41/Supplement_1/i198/8199366" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:hFOr9nPyWt4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Powerful generative models of protein-ligand structure have recently been proposed, but few of these methods support both flexible protein-ligand docking and affinity estimation. Of those that do, none can directly model multiple binding ligands concurrently or have been rigorously benchmarked on pharmacologically relevant drug targets, hindering their widespread adoption in drug discovery efforts. In this work, we propose FlowDock, a deep geometric generative model based on conditional flow matching that learns to directly map unbound (apo) structures to their bound (holo) counterparts for an arbitrary number of binding ligands. Furthermore, FlowDock provides predicted structural confidence scores and binding affinity values with each of its generated protein-ligand complex structures, enabling fast virtual screening of new (multi-ligand) drug targets. For the commonly-used PoseBusters Benchmark dataset, FlowDock achieves a 51% blind docking success rate using unbound (apo) protein input structures and without any information derived from multiple sequence alignments, and for the challenging new DockGen-E dataset, FlowDock matches the performance of single-sequence Chai-1 for binding pocket generalization. Additionally, in the ligand category of the 16th community-wide Critical Assessment of Techniques for Structure Prediction (CASP16), FlowDock ranked among the top-5 methods for pharmacological binding affinity estimation across 140 protein-ligand complexes, demonstrating the efficacy of its learned representations in virtual screening. Source code, data, and pre-trained models are available at https://github.com/BioinfoMachineLearning/FlowDock.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Proteins</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MULTICOM_ligand-480.webp 480w,/assets/img/publication_preview/MULTICOM_ligand-800.webp 800w,/assets/img/publication_preview/MULTICOM_ligand-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/MULTICOM_ligand.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MULTICOM_ligand.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025multicom" class="col-sm-8"> <div class="title">Protein-ligand structure and affinity prediction in CASP16 using a geometric deep learning ensemble and flow matching</div> <div class="author"> <em>Alex Morehead</em>, Jian Liu, Pawan Neupane, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nabin Giri, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Proteins: Structure, Function, and Bioinformatics</em>, 2025 </div> <div class="periodical"> Deep ensembling for protein-ligand structure and affinity prediction, presented as a CASP16 top-5 method </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/10.1002/prot.26827" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:mB3voiENLucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicting the structure of ligands bound to proteins is a foundational problem in modern biotechnology and drug discovery, yet little is known about how to combine the predictions of protein-ligand structure (poses) produced by the latest deep learning methods to identify the best poses and how to accurately estimate the binding affinity between a protein target and a list of ligand candidates. Further, a blind benchmarking and assessment of protein-ligand structure and binding affinity prediction is necessary to ensure it generalizes well to new settings. Towards this end, we introduce MULTICOM_ligand, a deep learning-based protein-ligand structure and binding affinity prediction ensemble featuring structural consensus ranking for unsupervised pose ranking and a new deep generative flow matching model for joint structure and binding affinity prediction. Notably, MULTICOM_ligand ranked among the top-5 ligand prediction methods in both protein-ligand structure prediction and binding affinity prediction in the 16th Critical Assessment of Techniques for Structure Prediction (CASP16), demonstrating its efficacy and utility for real-world drug discovery efforts. The source code for MULTICOM_ligand is freely available on GitHub.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">TMLR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/RNA-FrameFlow-480.webp 480w,/assets/img/publication_preview/RNA-FrameFlow-800.webp 800w,/assets/img/publication_preview/RNA-FrameFlow-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/RNA-FrameFlow.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="RNA-FrameFlow.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="anand2025rna" class="col-sm-8"> <div class="title">RNA-FrameFlow: Flow Matching for de novo 3D RNA Backbone Design</div> <div class="author"> Rishabh Anand<sup>*</sup>, Chaitanya K Joshi<sup>*</sup>, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Arian R Jamasb, Charles Harris, Simon V Matthis, Kieran Didi, Bryan Hooi, Pietro Liò' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2025 </div> <div class="periodical"> Conditional flow matching for geometric RNA structure design, selected as an ICML 2024 SPIGM (AI4Science) oral (spotlight) presentation </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=wOc1Yx5s09" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:qUcmZB5y_30C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score &gt;= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NMI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/PoseBench-480.webp 480w,/assets/img/publication_preview/PoseBench-800.webp 800w,/assets/img/publication_preview/PoseBench-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/PoseBench.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="PoseBench.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025posebench" class="col-sm-8"> <div class="title">Assessing the potential of deep learning for protein-ligand docking</div> <div class="author"> <em>Alex Morehead</em>, Nabin Giri, Jian Liu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Pawan Neupane, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Nature Machine Intelligence</em>, 2025 </div> <div class="periodical"> Comprehensive benchmarking and experimentation suite for protein-ligand docking and structure prediction, selected as an ICML AI4Science spotlight presentation (top 20% - 30/159) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2405.14108" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:IWHjjKOFINEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of the latest docking and structure prediction methods within the broadly applicable context of (1) using predicted (apo) protein structures for docking (e.g., for applicability to new proteins); (2) binding multiple (cofactor) ligands concurrently to a given target protein (e.g., for enzyme design); and (3) having no prior knowledge of binding pockets (e.g., for generalization to unknown pockets). To enable a deeper understanding of docking methods’ real-world utility, we introduce PoseBench, the first comprehensive benchmark for broadly applicable protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL methods for apo-to-holo protein-ligand docking and protein-ligand structure prediction using both primary ligand and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that (1) DL co-folding methods generally outperform comparable conventional and DL docking baseline algorithms, yet popular methods such as AlphaFold 3 are still challenged by prediction targets with novel binding poses; (2) certain DL co-folding methods are highly sensitive to their input multiple sequence alignments, while others are not; and (3) DL methods struggle to strike a balance between structural accuracy and chemical specificity when predicting novel or multi-ligand protein targets. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MU</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Dissertation-480.webp 480w,/assets/img/publication_preview/Dissertation-800.webp 800w,/assets/img/publication_preview/Dissertation-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Dissertation.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Dissertation.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025dissertation" class="col-sm-8"> <div class="title">Geometric deep learning and generative modeling of 3D biomolecules</div> <div class="author"> <em>Alex Morehead</em> </div> <div class="periodical"> <em>University of Missouri-Columbia</em>, 2025 </div> <div class="periodical"> PhD dissertation summarizing geometric deep learning and generative modeling advances for 3D biomolecules </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.proquest.com/dissertations-theses/geometric-deep-learning-generative-modeling-3d/docview/3280272557/se-2" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:4JMBOYKVnBMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Life’s molecules, ranging from small molecule ligands to large polymer proteins, are intricately responsible for the biomolecular functions that maintain life within and beyond a single cell. Nonetheless, such biomolecules and their structural roles in cellular biology remain poorly understood at the genomic scale owing to their complex inter-atomic interactions, necessitating the development of new computational methods for studying biomolecules at the atomic level. To address this issue, in this dissertation, I describe the development of a collection of deep learning methods (Geometric Transformers, GCPNet, GCDM, and FlowDock) for modeling increasingly complex biomolecular structures and interactions. These methods have advanced the state-of-the-art of deep learning in protein and biomolecular representation learning, generative modeling of 3D molecules, and protein-ligand structure and affinity prediction. Additionally, in this dissertation, I detail the design and results of a new deep learning benchmark (PoseBench) and ensembling prediction method (MULTICOM ligand) for standardized and broadly applicable protein-ligand docking and structure prediction. The findings of the former benchmark suggest that future work in deep learning for 3D biomolecules may benefit from stronger dataset splitting and out-of-distribution evaluation. Further, the latter ensembling method ranked as a top-5 method in the ligand prediction category of the 16th Critical Assessment of Techniques for Structure Prediction (CASP16). Taken together, this dissertation represents an advancement in our understanding of life’s molecules through the lens of deep learning as well as new insights and directions for future deep learning research in the physical and life sciences. All methods, benchmarks, and datasets described in this dissertation have been open sourced and made freely available to the scientific community.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS AI4Sci</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCP_VQVAE-480.webp 480w,/assets/img/publication_preview/GCP_VQVAE-800.webp 800w,/assets/img/publication_preview/GCP_VQVAE-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCP_VQVAE.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCP_VQVAE.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pourmirzaei2025gcp" class="col-sm-8"> <div class="title">GCP-VQVAE: A Geometry-Complete Language for Protein 3D Structure</div> <div class="author"> Mahdi Pourmirzaei, <em>Alex Morehead</em>, Farzaneh Esmaili, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Jarett Ren, Mohammadreza Pourmirzaei, Dong Xu' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In NeurIPS AI4Science Workshop</em>, 2025 </div> <div class="periodical"> Tokenizing 3D protein structures into a geometry-complete language </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.biorxiv.org/content/10.1101/2025.10.01.679833v1.abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:iH-uZ7U-co4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Converting protein tertiary structure into discrete tokens via vector-quantized variational autoencoders (VQ-VAEs) creates a language of 3D geometry and provides a natural interface between sequence and structure models. While pose invariance is commonly enforced, retaining chirality and directional cues without sacrificing reconstruction accuracy remains challenging. In this paper, we introduce GCPVQVAE, a geometry-complete tokenizer built around a strictly SE(3)-equivariant GCPNet encoder that preserves orientation and chirality of protein backbones. We vector-quantize rotation/translation-invariant readouts that retain chirality into a 4,096-token vocabulary, and a transformer decoder maps tokens back to backbone coordinates via a 6D rotation head trained with SE(3)-invariant objectives. Building on these properties, we train GCP-VQVAE on a corpus of 24 million monomer protein backbone structures gathered from the AlphaFold Protein Structure Database. On the CAMEO2024, CASP15, and CASP16 evaluation datasets, the model achieves backbone RMSDs of 0.4377 Å, 0.5293 Å, and 0.7567 Å, respectively, and achieves 100% codebook utilization on a held-out validation set, substantially outperforming prior VQ-VAE-based tokenizers and achieving state-of-the-art performance. Beyond these benchmarks, on a zero-shot set of 1,938 completely new experimental structures, GCP-VQVAE attains a backbone RMSD of 0.8193 Å and a TM-score of 0.9673, demonstrating robust generalization to unseen proteins. Lastly, we elaborate on the various applications of this foundation-like model, such as protein structure compression and the integration of generative protein language models. We make the GCP-VQVAE source code, zero-shot dataset, and its pretrained weights fully open for the research community: https://github.com/mahdip72/vq_encoder_decoder.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MoML</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/TransIP-480.webp 480w,/assets/img/publication_preview/TransIP-800.webp 800w,/assets/img/publication_preview/TransIP-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/TransIP.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="TransIP.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="elhag2025learning" class="col-sm-8"> <div class="title">Learning Inter-Atomic Potentials without Explicit Equivariance</div> <div class="author"> Ahmed A Elhag, Arun Raja, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Samuel M Blau, Garrett M Morris, Michael M Bronstein' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In NeurIPS Machine Learning in Structural Biology (MLSB) Workshop</em>, 2025 </div> <div class="periodical"> Architecture-agnostic equivariance learning for inter-atomic potentials </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2510.00027" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:r0BpntZqJG4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Accurate and scalable machine-learned inter-atomic potentials (MLIPs) are essential for molecular simulations ranging from drug discovery to new material design. Current state-of-the-art models enforce roto-translational symmetries through equivariant neural network architectures, a hard-wired inductive bias that can often lead to reduced flexibility, computational efficiency, and scalability. In this work, we introduce TransIP: Transformer-based Inter-Atomic Potentials, a novel training paradigm for interatomic potentials achieving symmetry compliance without explicit architectural constraints. Our approach guides a generic non-equivariant Transformer-based model to learn SO(3)-equivariance by optimizing its representations in the embedding space. Trained on the recent Open Molecules (OMol25) collection, a large and diverse molecular dataset built specifically for MLIPs and covering different types of molecules (including small organics, biomolecular fragments, and electrolyte-like species), TransIP effectively learns symmetry in its latent space, providing low equivariance error. Further, compared to a data augmentation baseline, TransIP achieves 40% to 60% improvement in performance across varying OMol25 dataset sizes. More broadly, our work shows that learned equivariance can be a powerful and efficient alternative to augmentation-based MLIP models.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MegaFold-480.webp 480w,/assets/img/publication_preview/MegaFold-800.webp 800w,/assets/img/publication_preview/MegaFold-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/MegaFold.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MegaFold.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="la2025megafold" class="col-sm-8"> <div class="title">MegaFold: System-Level Optimizations for Accelerating Protein Structure Prediction Models</div> <div class="author"> Hoa La, Ahan Gupta, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jianlin Cheng, Minjia Zhang' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv</em>, 2025 </div> <div class="periodical"> Accelerating biomolecular structure prediction with system-level optimizations </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2506.20686" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:R3hNpaxXUhUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Protein structure prediction models such as AlphaFold3 (AF3) push the frontier of biomolecular modeling by incorporating science-informed architectural changes to the transformer architecture. However, these advances come at a steep system cost, introducing: compute- and memory-intensive operators, 2D attention mechanisms, and retrieval-augmented data pipelines, which collectively hinder the scalability of AF3 training. In this work, we present MegaFold, a cross-platform system to accelerate AF3 training. MegaFold tackles key bottlenecks through ahead-of-time caching to eliminate GPU idle time from the retrieval-augmented data pipeline, Triton-based kernels for memory-efficient EvoAttention on heterogeneous devices, and deep fusion for common and critical small operators in AF3. Evaluation on both NVIDIA H200 and AMD MI250 GPUs shows that MegaFold reduces peak memory usage of AF3 training by up to 1.23 and improves per-iteration training time by up-to 1.73 and 1.62 respectively. More importantly, MegaFold enables training on 1.35 longer sequence lengths compared to PyTorch baselines without running out-of-memory, significantly improving the scalability of modern protein folding models. We open source our code at https://github.com/Supercomputing-System-AI-Lab/MegaFold/.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Authorea</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Flow_Matching_Review-480.webp 480w,/assets/img/publication_preview/Flow_Matching_Review-800.webp 800w,/assets/img/publication_preview/Flow_Matching_Review-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Flow_Matching_Review.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Flow_Matching_Review.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2025go" class="col-sm-8"> <div class="title">Flow matching in bioinformatics and computational biology</div> <div class="author"> <em>Alex Morehead</em>, Lazar Atanackovic, Akshata Hegde, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Yanli Wang, Frimpong Boadu, Joel Selvaraj, Alexander Tong, Aditi Krishnapriyan, Jianlin Cheng' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>Authorea Preprints</em>, 2025 </div> <div class="periodical"> Characterizing the landscape of flow matching theory and applications in bioinformatics </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.authorea.com/doi/full/10.22541/au.175382408.89466370" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:_Qo2XoVZTnwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Numerous problems in bioinformatics and computational biology can be framed as a task of learning a mapping from one state of a biological system to another relevant state or to explore novel data points across biologically-constrained spaces. However, manually deriving such mappings (e.g., to transform cells in a diseased state back into a healthy state) or extrapolating from existing datasets to create new data (e.g., for molecular design) is often nontrivial and can require extraordinary domain expertise and resources. Fortunately, the field of generative artificial intelligence (AI) has introduced a new training paradigm referred to as (conditional) flow matching, which has emerged as a promising solution to this problem, with broad applicability in computer vision, natural language processing, and the physical and life sciences. Flow matching is a powerful and principled (data-driven) framework for efficiently learning a mapping between arbitrary pairs of high-dimensional data distributions, making it well suited for addressing problems in molecular and cell biology. In this Review, we characterize the theoretical foundations of flow matching and its applications in biomolecular modeling (e.g., for proteins, DNA/RNA, small molecules, and their interactions) and single/multi-cellular modeling (e.g., for cell phenotyping and imaging), each contributing towards the development of an AI-based virtual cell. Lastly, this review highlights open-source flow matching methods and discusses future directions in flow-based generative modeling for bioinformatics and computational biology.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Topotein-480.webp 480w,/assets/img/publication_preview/Topotein-800.webp 800w,/assets/img/publication_preview/Topotein-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Topotein.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Topotein.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2025topotein" class="col-sm-8"> <div class="title">Topotein: Topological Deep Learning for Protein Representation Learning</div> <div class="author"> Zhiyu Wang, Arian Jamasb, Mustafa Hajij, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Alex Morehead, Luke Braithwaite, Pietro Liò' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>arXiv</em>, 2025 </div> <div class="periodical"> Topological graph neural networks for learning protein representations hierarchically </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2509.03885" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:j3f4tGmQtD8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Protein representation learning (PRL) is crucial for understanding structure-function relationships, yet current sequence- and graph-based methods fail to capture the hierarchical organization inherent in protein structures. We introduce Topotein, a comprehensive framework that applies topological deep learning to PRL through the novel Protein Combinatorial Complex (PCC) and Topology-Complete Perceptron Network (TCPNet). Our PCC represents proteins at multiple hierarchical levels – from residues to secondary structures to complete proteins – while preserving geometric information at each level. TCPNet employs SE(3)-equivariant message passing across these hierarchical structures, enabling more effective capture of multi-scale structural patterns. Through extensive experiments on four PRL tasks, TCPNet consistently outperforms state-of-the-art geometric graph neural networks. Our approach demonstrates particular strength in tasks such as fold classification which require understanding of secondary structure arrangements, validating the importance of hierarchical topological features for protein analysis.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://academic.oup.com/bioinformatics" rel="external nofollow noopener" target="_blank">Bioinformatics</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCPNet-480.webp 480w,/assets/img/publication_preview/GCPNet-800.webp 800w,/assets/img/publication_preview/GCPNet-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCPNet.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCPNet.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024geometry" class="col-sm-8"> <div class="title">Geometry-Complete Perceptron Networks for 3D Molecular Graphs</div> <div class="author"> <em>Alex Morehead</em>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Bioinformatics</em>, 2024 </div> <div class="periodical"> Chirality-aware vector message passing, also presented at the AAAI 2023 DLG (poster) and AI2ASE (oral presentation) workshops </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article/40/2/btae087/7610880" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:ULOm3_A8WrAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Motivation: The field of geometric deep learning has recently had a profound impact on several scientific domains such as protein structure prediction and design, leading to methodological advancements within and outside of the realm of traditional machine learning. Within this spirit, in this work, we introduce GCPNET, a new chirality-aware SE(3)-equivariant graph neural network designed for representation learning of 3D biomolecular graphs. We show that GCPNET, unlike previous representation learning methods for 3D biomolecules, is widely applicable to a variety of invariant or equivariant node-level, edge-level, and graph-level tasks on biomolecular structures while being able to (1) learn important chiral properties of 3D molecules and (2) detect external force fields. Results: Across four distinct molecular-geometric tasks, we demonstrate that GCPNET’s predictions (1) for protein–ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5%, greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged mean squared error less than 0.01, more than 15% better than current methods; and (4) for molecular chirality recognition achieve a state-of-the-art prediction accuracy of 98.7%, better than any other machine learning method to date. Availability and implementation: The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/GCPNet.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://www.nature.com/commschem/" rel="external nofollow noopener" target="_blank">CommsChem</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCDM-480.webp 480w,/assets/img/publication_preview/GCDM-800.webp 800w,/assets/img/publication_preview/GCDM-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCDM.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCDM.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024diffusion" class="col-sm-8"> <div class="title">Geometry-Complete Diffusion for 3D Molecule Generation and Optimization</div> <div class="author"> <em>Alex Morehead</em>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Communications Chemistry</em>, 2024 </div> <div class="periodical"> Chirality-aware diffusion generative model of 3D molecules, also presented at the ICLR 2023 MLDD workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s42004-024-01233-z" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:M3ejUd6NZC8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Denoising diffusion probabilistic models (DDPMs) have recently taken the field of generative modeling by storm, pioneering new state-of-the-art results in disciplines such as computer vision and computational biology for diverse tasks ranging from text-guided image generation to structure-guided protein design. Along this latter line of research, methods such as those of Hoogeboom et al. 2022 have been proposed for generating 3D molecules using equivariant graph neural networks (GNNs) within a DDPM framework. Toward this end, we propose GCDM, a geometry-complete diffusion model that achieves new state-of-the-art results for 3D molecule diffusion generation by leveraging the representation learning strengths offered by GNNs that perform geometry-complete message-passing. Our results with GCDM also offer preliminary insights into how physical inductive biases impact the generative dynamics of molecular DDPMs. The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/Bio-Diffusion.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Protein Science</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/GCPNet-EMA-480.webp 480w,/assets/img/publication_preview/GCPNet-EMA-800.webp 800w,/assets/img/publication_preview/GCPNet-EMA-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/GCPNet-EMA.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="GCPNet-EMA.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2024gcpnet_ema" class="col-sm-8"> <div class="title">Protein Structure Accuracy Estimation using Geometry-Complete Perceptron Networks</div> <div class="author"> <em>Alex Morehead</em>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>Protein Science</em>, 2024 </div> <div class="periodical"> Follow-up work with GCPNet for fast protein structure accuracy estimation </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/pro.4932" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:9ZlFYXVOiuMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Estimating the accuracy of protein structural models is a critical task in protein bioinformatics. The need for robust methods in the estimation of protein model accuracy (EMA) is prevalent in the field of protein structure prediction, where computationally-predicted structures need to be screened rapidly for the reliability of the positions predicted for each of their amino acid residues and their overall quality. Current methods proposed for EMA are either coupled tightly to existing protein structure prediction methods or evaluate protein structures without sufficiently leveraging the rich, geometric information available in such structures to guide accuracy estimation. In this work, we propose a geometric message passing neural network referred to as the geometry-complete perceptron network for protein structure EMA (GCPNet-EMA), where we demonstrate through rigorous computational benchmarks that GCPNet-EMA’s accuracy estimations are 47% faster and more than 10% (6%) more correlated with ground-truth measures of per-residue (per-target) structural accuracy compared to baseline state-of-the-art methods for tertiary (multimer) structure EMA including AlphaFold 2. The source code and data for GCPNet-EMA are available on GitHub, and a public web server implementation is freely available.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/ProteinWorkshop-480.webp 480w,/assets/img/publication_preview/ProteinWorkshop-800.webp 800w,/assets/img/publication_preview/ProteinWorkshop-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/ProteinWorkshop.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="ProteinWorkshop.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="jamasb2024evaluating" class="col-sm-8"> <div class="title">Evaluating Representation Learning on the Protein Structure Universe</div> <div class="author"> Arian R. Jamasb<sup>*</sup>, <em>Alex Morehead<sup>*</sup></em>, Chaitanya K. Joshi<sup>*</sup>, and <span class="more-authors" title="click to view 8 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '8 more authors' ? 'Zuobai Zhang&lt;sup&gt;*&lt;/sup&gt;, Kieran Didi, Simon V. Mathis, Charles Harris, Jian Tang, Jianlin Cheng, Pietro Lio, Tom L. Blundell' : '8 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">8 more authors</span> </div> <div class="periodical"> <em>In The Twelth International Conference on Learning Representations (ICLR)</em>, 2024 </div> <div class="periodical"> Comprehensive benchmarking and experimentation suite for protein representation learning, also presented at the NeurIPS 2023 MLSB workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=sTYuRVrdK3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:mVmsd5A6BfQC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models. We aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CASP15</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/CASP15-CAPRI-480.webp 480w,/assets/img/publication_preview/CASP15-CAPRI-800.webp 800w,/assets/img/publication_preview/CASP15-CAPRI-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/CASP15-CAPRI.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="CASP15-CAPRI.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="https://doi.org/10.1002/prot.26609" class="col-sm-8"> <div class="title">Impact of AlphaFold on structure prediction of protein complexes: The CASP15-CAPRI experiment</div> <div class="author"> Marc F. Lensink, Guillaume Brysbaert, Nessim Raouraoua, and <span class="more-authors" title="click to view 110 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '110 more authors' ? 'Paul A. Bates, Marco Giulini, Rodrigo V. Honorato, Charlotte Noort, Joao M. C. Teixeira, Alexandre M. J. J. Bonvin, Ren Kong, Hang Shi, Xufeng Lu, Shan Chang, Jian Liu, Zhiye Guo, Xiao Chen, Alex Morehead, Raj S. Roy, Tianqi Wu, Nabin Giri, Farhan Quadir, Chen Chen, Jianlin Cheng, Carlos A. Del Carpio, Eichiro Ichiishi, Luis A. Rodriguez-Lumbreras, Juan Fernandez-Recio, Ameya Harmalkar, Lee-Shin Chu, Sam Canner, Rituparna Smanta, Jeffrey J. Gray, Hao Li, Peicong Lin, Jiahua He, Huanyu Tao, Sheng-You Huang, Jorge Roel-Touris, Brian Jimenez-Garcia, Charles W. Christoffer, Anika J. Jain, Yuki Kagaya, Harini Kannan, Tsukasa Nakamura, Genki Terashi, Jacob C. Verburgt, Yuanyuan Zhang, Zicong Zhang, Hayato Fujuta, Masakazu Sekijima, Daisuke Kihara, Omeir Khan, Sergei Kotelnikov, Usman Ghani, Dzmitry Padhorny, Dmitri Beglov, Sandor Vajda, Dima Kozakov, Surendra S. Negi, Tiziana Ricciardelli, Didier Barradas-Bautista, Zhen Cao, Mohit Chawla, Luigi Cavallo, Romina Oliva, Rui Yin, Melyssa Cheung, Johnathan D. Guest, Jessica Lee, Brian G. Pierce, Ben Shor, Tomer Cohen, Matan Halfon, Dina Schneidman-Duhovny, Shaowen Zhu, Rujie Yin, Yuanfei Sun, Yang Shen, Martyna Maszota-Zieleniak, Krzysztof K. Bojarski, Emilia A. Lubecka, Mateusz Marcisz, Annemarie Danielsson, Lukasz Dziadek, Margrethe Gaardlos, Artur Gieldon, Adam Liwo, Sergey A. Samsonov, Rafal Slusarz, Karolina Zieba, Adam K. Sieradzan, Cezary Czaplewski, Shinpei Kobayashi, Yuta Miyakawa, Yasuomi Kiyota, Mayuko Takeda-Shitaka, Kliment Olechnovic, Lukas Valancauskas, Justas Dapkunas, Ceslovas Venclovas, Bjorn Wallner, Lin Yang, Chengyu Hou, Xiaodong He, Shuai Guo, Shenda Jiang, Xiaoliang Ma, Rui Duan, Liming Qui, Xianjin Xu, Xiaoqin Zou, Sameer Velankar, Shoshana J. Wodak' : '110 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">110 more authors</span> </div> <div class="periodical"> <em>Proteins: Structure, Function, and Bioinformatics</em>, 2023 </div> <div class="periodical"> Analysis of the CASP15-CAPRI experiment’s results </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.26609" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:aqlVkmm33-oC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We present the results for CAPRI Round 54, the 5th joint CASP-CAPRI protein assembly prediction challenge. The Round offered 37 targets, including 14 homodimers, 3 homo-trimers, 13 heterodimers including 3 antibody–antigen complexes, and 7 large assemblies. On average  70 CASP and CAPRI predictor groups, including more than 20 automatics servers, submitted models for each target. A total of 21 941 models submitted by these groups and by 15 CAPRI scorer groups were evaluated using the CAPRI model quality measures and the DockQ score consolidating these measures. The prediction performance was quantified by a weighted score based on the number of models of acceptable quality or higher submitted by each group among their five best models. Results show substantial progress achieved across a significant fraction of the 60+ participating groups. High-quality models were produced for about 40% of the targets compared to 8% two years earlier. This remarkable improvement is due to the wide use of the AlphaFold2 and AlphaFold2-Multimer software and the confidence metrics they provide. Notably, expanded sampling of candidate solutions by manipulating these deep learning inference engines, enriching multiple sequence alignments, or integration of advanced modeling tools, enabled top performing groups to exceed the performance of a standard AlphaFold2-Multimer version used as a yard stick. This notwithstanding, performance remained poor for complexes with antibodies and nanobodies, where evolutionary relationships between the binding partners are lacking, and for complexes featuring conformational flexibility, clearly indicating that the prediction of protein complexes remains a challenging problem.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ISMB</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Gated_Graph_Transformer-480.webp 480w,/assets/img/publication_preview/Gated_Graph_Transformer-800.webp 800w,/assets/img/publication_preview/Gated_Graph_Transformer-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Gated_Graph_Transformer.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Gated_Graph_Transformer.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1093/bioinformatics/btad203" class="col-sm-8"> <div class="title">A gated graph transformer for protein complex structure quality assessment and its performance in CASP15</div> <div class="author"> Xiao Chen<sup>*</sup>, <em>Alex Morehead<sup>*</sup></em>, Jian Liu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jianlin Cheng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Intelligent Systems for Molecular Biology (ISMB)</em>, 2023 </div> <div class="periodical"> Follow-up work to Geometric Transformers, presented at ISMB 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article/39/Supplement_1/i308/7210460" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:qxL8FJ1GzNcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Proteins interact to form complexes to carry out essential biological functions. Computational methods such as AlphaFold-multimer have been developed to predict the quaternary structures of protein complexes. An important yet largely unsolved challenge in protein complex structure prediction is to accurately estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. In this work, we introduce a new gated neighborhood-modulating graph transformer to predict the quality of 3D protein complex structures. It incorporates node and edge gates within a graph transformer framework to control information flow during graph message passing. We trained, evaluated and tested the method (called DProQA) on newly-curated protein complex datasets before the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) and then blindly tested it in the 2022 CASP15 experiment. The method was ranked 3rd among the single-model quality assessment methods in CASP15 in terms of the ranking loss of TM-score on 36 complex targets. The rigorous internal and external experiments demonstrate that DProQA is effective in ranking protein complex structures. The source code, data, and pre-trained models are available at https://github.com/jianlin-cheng/DProQA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://www.mlsb.io/" rel="external nofollow noopener" target="_blank">NeurIPS MLSB</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/MMDiff-480.webp 480w,/assets/img/publication_preview/MMDiff-800.webp 800w,/assets/img/publication_preview/MMDiff-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/MMDiff.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="MMDiff.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2023towards" class="col-sm-8"> <div class="title">Towards Joint Sequence-Structure Generation of Nucleic Acid and Protein Complexes</div> <div class="author"> <em>Alex Morehead</em>, Aadyot Bhatnagar, Jeffrey A. Ruffolo, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Ali Madani' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In NeurIPS Machine Learning in Structural Biology (MLSB) Workshop</em>, 2023 </div> <div class="periodical"> First generative model of protein and nucleic acid biomolecules </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.mlsb.io/papers_2023/Towards_Joint_Sequence-Structure_Generation_of_Nucleic_Acid_and_Protein_Complexes_with_SE3-Discrete_Diffusion.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Wp0gIr-vW9MC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Scientific Data</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DIPS-Plus.webp" sizes="200px"></source> <img src="/assets/img/publication_preview/DIPS-Plus.webp" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DIPS-Plus.webp" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Morehead_2023" class="col-sm-8"> <div class="title">DIPS-Plus: The enhanced database of interacting protein structures for interface prediction</div> <div class="author"> <em>Alex Morehead</em>, Chen Chen, Ada Sedova, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Jianlin Cheng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Scientific Data</em>, 2023 </div> <div class="periodical"> At release, the largest annotated dataset of protein-protein structural interactions for machine learning, now part of OMol25 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.nature.com/articles/s41597-023-02409-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In this work, we expand on a dataset recently introduced for protein interface prediction (PIP), the Database of Interacting Protein Structures (DIPS), to present DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for machine learning of protein interfaces. While the original DIPS dataset contains only the Cartesian coordinates for atoms contained in the protein complex along with their types, DIPS-Plus contains multiple residue-level features including surface proximities, half-sphere amino acid compositions, and new profile hidden Markov model (HMM)-based sequence features for each amino acid, providing researchers a curated feature bank for training protein interface prediction methods. We demonstrate through rigorous benchmarks that training an existing state-of-the-art (SOTA) model for PIP on DIPS-Plus yields new SOTA results, surpassing the performance of some of the latest models trained on residue-level and atom-level encodings of protein complexes to date.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICMLA</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/SSL_with_GNNs_and_DR-480.webp 480w,/assets/img/publication_preview/SSL_with_GNNs_and_DR-800.webp 800w,/assets/img/publication_preview/SSL_with_GNNs_and_DR-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/SSL_with_GNNs_and_DR.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="SSL_with_GNNs_and_DR.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2023semi" class="col-sm-8"> <div class="title">Semi-Supervised Graph Learning Meets Dimensionality Reduction</div> <div class="author"> <em>Alex Morehead<sup>*</sup></em>, Watchanan Chantapakul<sup>*</sup>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In IEEE International Conference on Machine Learning and Applications</em>, 2023 </div> <div class="periodical"> First characterization of the interplay between dimensionality reduction and semi-supervised graph deep learning </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/10460069/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:5nxA0vEk-isC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Semi-supervised learning (SSL) has recently received increased attention from machine learning researchers. By enabling effective propagation of known labels in graph-based deep learning (GDL) algorithms, SSL is poised to become an increasingly used technique in GDL in the coming years. However, there are currently few explorations in the graph-based SSL literature on exploiting classical dimensionality reduction techniques for improved label propagation. In this work, we investigate the use of dimensionality reduction techniques such as PCA, t-SNE, and UMAP to see their effect on the performance of graph neural networks (GNNs) designed for semi-supervised propagation of node labels. Our study makes use of benchmark semi-supervised GDL datasets such as the Cora and Citeseer datasets to allow meaningful comparisons of the representations learned by each algorithm when paired with a dimensionality reduction technique. Our comprehensive benchmarks and clus-tering visualizations quantitatively and qualitatively demonstrate that, under certain conditions, employing a priori and a posteriori dimensionality reduction to GNN inputs and outputs, respectively, can simultaneously improve the effectiveness of semi-supervised node label propagation and node clustering. Our source code is freely available on GitHub.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://academic.oup.com/bioinformatics" rel="external nofollow noopener" target="_blank">Bioinformatics</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EnQA-480.webp 480w,/assets/img/publication_preview/EnQA-800.webp 800w,/assets/img/publication_preview/EnQA-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/EnQA.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EnQA.jpeg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1093/bioinformatics/btad030" class="col-sm-8"> <div class="title">3D-equivariant graph neural networks for protein model quality assessment</div> <div class="author"> Chen Chen, Xiao Chen, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Tianqi Wu, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Bioinformatics</em>, 2023 </div> <div class="periodical"> Follow-up to Geometric Transformers introducing line graph message passing to equivariant graph neural networks </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://academic.oup.com/bioinformatics/article-abstract/39/1/btad030/6986970" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Quality assessment (QA) of predicted protein tertiary structure models plays an important role in ranking and using them. With the recent development of deep learning end-to-end protein structure prediction techniques for generating highly confident tertiary structures for most proteins, it is important to explore corresponding QA strategies to evaluate and select the structural models predicted by them since these models have better quality and different properties than the models predicted by traditional tertiary structure prediction methods. We develop EnQA, a novel graph-based 3D-equivariant neural network method that is equivariant to rotation and translation of 3D objects to estimate the accuracy of protein structural models by leveraging the structural features acquired from the state-of-the-art tertiary structure prediction method—AlphaFold2. We train and test the method on both traditional model datasets (e.g. the datasets of the Critical Assessment of Techniques for Protein Structure Prediction) and a new dataset of high-quality structural models predicted only by AlphaFold2 for the proteins whose experimental structures were released recently. Our approach achieves state-of-the-art performance on protein structural models predicted by both traditional protein structure prediction methods and the latest end-to-end deep learning method—AlphaFold2. It performs even better than the model QA scores provided by AlphaFold2 itself. The results illustrate that the 3D-equivariant graph neural network is a promising approach to the evaluation of protein structural models. Integrating AlphaFold2 features with other complementary sequence and structural features is important for improving protein model QA. The source code is available at https://github.com/BioinfoMachineLearning/EnQA.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">bioRxiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Geometric_Mutation_Prediction-480.webp 480w,/assets/img/publication_preview/Geometric_Mutation_Prediction-800.webp 800w,/assets/img/publication_preview/Geometric_Mutation_Prediction-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Geometric_Mutation_Prediction.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Geometric_Mutation_Prediction.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="mahmud2023accurate" class="col-sm-8"> <div class="title">Accurate prediction of protein tertiary structural changes induced by single-site mutations with equivariant graph neural networks</div> <div class="author"> Sajid Mahmud, <em>Alex Morehead</em>, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>bioRxiv</em>, 2023 </div> <div class="periodical"> First deep learning method to model single-site structural changes in proteins </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.biorxiv.org/content/10.1101/2023.10.03.560758.abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:4DMP91E08xMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicting the change of protein tertiary structure caused by singlesite mutations is important for studying protein structure, function, and interaction. Even though computational protein structure prediction methods such as AlphaFold can predict the overall tertiary structures of most proteins rather accurately, they are not sensitive enough to accurately predict the structural changes induced by single-site amino acid mutations on proteins. Specialized mutation prediction methods mostly focus on predicting the overall stability or function changes caused by mutations without attempting to predict the exact mutation-induced structural changes, limiting their use in protein mutation study. In this work, we develop the first deep learning method based on equivariant graph neural networks (EGNN) to directly predict the tertiary structural changes caused by single-site mutations and the tertiary structure of any protein mutant from the structure of its wild-type counterpart. The results show that it performs substantially better in predicting the tertiary structures of protein mutants than the widely used protein structure prediction method AlphaFold.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICIBM</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/DRLComplex-480.webp 480w,/assets/img/publication_preview/DRLComplex-800.webp 800w,/assets/img/publication_preview/DRLComplex-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/DRLComplex.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="DRLComplex.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="soltanikazemi2023drlcomplex" class="col-sm-8"> <div class="title">DRLComplex: Reconstruction of protein quaternary structures using deep reinforcement learning</div> <div class="author"> Elham Soltanikazemi, Raj S Roy, Farhan Quadir, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Nabin Giri, Alex Morehead, Jianlin Cheng' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In International Conference on Intelligent Biology and Medicine</em>, 2023 </div> <div class="periodical"> First deep Q-learning algorithm for protein complex structure modeling </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2205.13594" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Zph67rFs4hoC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Predicted inter-chain residue-residue contacts can be used to build the quaternary structure of protein complexes from scratch. However, only a small number of methods have been developed to reconstruct protein quaternary structures using predicted inter-chain contacts. Here, we present an agent-based self-learning method based on deep reinforcement learning (DRLComplex) to build protein complex structures using inter-chain contacts as distance constraints. We rigorously tested DRLComplex on two standard datasets of homodimeric and heterodimeric protein complexes (i.e., the CASP-CAPRI homodimer and Std_32 heterodimer datasets) using both true and predicted interchain contacts as inputs. Utilizing true contacts as input, DRLComplex achieved high average TM-scores of 0.9895 and 0.9881 and a low average interface RMSD (I_RMSD) of 0.2197 and 0.92 on the two datasets, respectively. When predicted contacts are used, the method achieves TM-scores of 0.73 and 0.76 for homodimers and heterodimers, respectively. Our experiments find that the accuracy of reconstructed quaternary structures depends on the accuracy of the contact predictions. Compared to other optimization methods for reconstructing quaternary structures from inter-chain contacts, DRLComplex performs similar to an advanced gradient descent method and better than a Markov Chain Monte Carlo simulation method and a simulated annealing-based method, validating the effectiveness of DRLComplex for quaternary reconstruction of protein complexes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">bioRxiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Antibody_Design_with_Generative_AI-480.webp 480w,/assets/img/publication_preview/Antibody_Design_with_Generative_AI-800.webp 800w,/assets/img/publication_preview/Antibody_Design_with_Generative_AI-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Antibody_Design_with_Generative_AI.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Antibody_Design_with_Generative_AI.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Shanehsazzadeh2023.01.08.523187" class="col-sm-8"> <div class="title">Unlocking de novo antibody design with generative artificial intelligence</div> <div class="author"> Amir Shanehsazzadeh, Sharrol Bachas, Matt McPartlon, and <span class="more-authors" title="click to view 43 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '43 more authors' ? 'George Kasun, John M. Sutton, Andrea K. Steiger, Richard Shuai, Christa Kohnert, Goran Rakocevic, Jahir M. Gutierrez, Chelsea Chung, Breanna K. Luton, Nicolas Diaz, Simon Levine, Julian Alverio, Bailey Knight, Macey Radach, Alex Morehead, Katherine Bateman, David A. Spencer, Zachary McDargh, Jovan Cejovic, Gaelin Kopec-Belliveau, Robel Haile, Edriss Yassine, Cailen McCloskey, Monica Natividad, Dalton Chapman, Joshua Bennett, Jubair Hossain, Abigail B. Ventura, Gustavo M. Canales, Muttappa Gowda, Kerianne A. Jackson, Jennifer T. Stanton, Marcin Ura, Luka Stojanovic, Engin Yapici, Katherine Moran, Rodante Caguiat, Amber Brown, Shaheed Abdulhaqq, Zheyuan Guo, Lillian R. Klug, Miles Gander, Joshua Meier' : '43 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">43 more authors</span> </div> <div class="periodical"> <em>bioRxiv</em>, 2023 </div> <div class="periodical"> Follow-up work presented at the NeurIPS 2023 MLSB workshop </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.biorxiv.org/content/10.1101/2023.01.08.523187.abstract" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:4TOpqqG69KYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of  106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with  3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100"> <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank">ICLR</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Geometric_Transformer-480.webp 480w,/assets/img/publication_preview/Geometric_Transformer-800.webp 800w,/assets/img/publication_preview/Geometric_Transformer-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Geometric_Transformer.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Geometric_Transformer.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2022geometric" class="col-sm-8"> <div class="title">Geometric Transformers for Protein Interface Contact Prediction</div> <div class="author"> <em>Alex Morehead</em>, Chen Chen, and <a href="https://calla.rnet.missouri.edu/cheng/" rel="external nofollow noopener" target="_blank">Jianlin Cheng</a> </div> <div class="periodical"> <em>In The Tenth International Conference on Learning Representations (ICLR)</em>, 2022 </div> <div class="periodical"> Presented a new line graph message passing transformer at ICLR 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openreview.net/forum?id=CS4463zx6Hi" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:Se3iqnhoufwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/EGR-480.webp 480w,/assets/img/publication_preview/EGR-800.webp 800w,/assets/img/publication_preview/EGR-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/EGR.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="EGR.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead2022egr" class="col-sm-8"> <div class="title">EGR: Equivariant Graph Refinement and Assessment of 3D Protein Complex Structures</div> <div class="author"> <em>Alex Morehead</em>, Xiao Chen, Tianqi Wu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jian Liu, Jianlin Cheng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>arXiv</em>, 2022 </div> <div class="periodical"> First deep learning method for joint protein-ligand complex structure quality assessment and refinement </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2205.10390" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:KlAtU1dfN6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Protein complexes are macromolecules essential to the functioning and well-being of all living organisms. As the structure of a protein complex, in particular its region of interaction between multiple protein subunits (i.e., chains), has a notable influence on the biological function of the complex, computational methods that can quickly and effectively be used to refine and assess the quality of a protein complex’s 3D structure can directly be used within a drug discovery pipeline to accelerate the development of new therapeutics and improve the efficacy of future vaccines. In this work, we introduce the Equivariant Graph Refiner (EGR), a novel E(3)-equivariant graph neural network (GNN) for multi-task structure refinement and assessment of protein complexes. Our experiments on new, diverse protein complex datasets, all of which we make publicly available in this work, demonstrate the state-of-the-art effectiveness of EGR for atomistic refinement and assessment of protein complexes and outline directions for future work in the field. In doing so, we establish a baseline for future studies in macromolecular refinement and structure analysis.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">CVPR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Automated_Retail_Checkout-480.webp 480w,/assets/img/publication_preview/Automated_Retail_Checkout-800.webp 800w,/assets/img/publication_preview/Automated_Retail_Checkout-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Automated_Retail_Checkout.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Automated_Retail_Checkout.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Shoman_2022_CVPR" class="col-sm-8"> <div class="title">A Region-Based Deep Learning Approach to Automated Retail Checkout</div> <div class="author"> Maged Shoman, Armstrong Aboah, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ye Duan, Abdulateef Daud, Yaw Adu-Gyamfi' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>, 2022 </div> <div class="periodical"> Instilling computer vision networks with industrial inductive biases for automated retail checkout </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Shoman_A_Region-Based_Deep_Learning_Approach_to_Automated_Retail_Checkout_CVPRW_2022_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Automating the product checkout process at conventional retail stores is a task poised to have large impacts on society generally speaking. Towards this end, reliable deep learning models that enable automated product counting for fast customer checkout can make this goal a reality. In this work, we propose a novel, region-based deep learning approach to automate product counting using a customized YOLOv5 object detection pipeline and the DeepSORT algorithm. Our results on challenging, real-world test videos demonstrate that our method can generalize its predictions to a sufficient level of accuracy and with a fast enough runtime to warrant deployment to real-world commercial settings. Our proposed method won 4th place in the 2022 AI City Challenge, Track 4, with an F1 score of 0.4400 on experimental validation data.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">MLHPC</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Genome-Scale_Protein_Structure-480.webp 480w,/assets/img/publication_preview/Genome-Scale_Protein_Structure-800.webp 800w,/assets/img/publication_preview/Genome-Scale_Protein_Structure-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Genome-Scale_Protein_Structure.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Genome-Scale_Protein_Structure.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="gao_9652872" class="col-sm-8"> <div class="title">High-Performance Deep Learning Toolbox for Genome-Scale Prediction of Protein Structure and Function</div> <div class="author"> Mu Gao, Peik Lund-Andersen, <em>Alex Morehead</em>, and <span class="more-authors" title="click to view 14 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '14 more authors' ? 'Sajid Mahmud, Chen Chen, Xiao Chen, Nabin Giri, Raj S. Roy, Farhan Quadir, T. Chad Effler, Ryan Prout, Subil Abraham, Wael Elwasif, N. Quentin Haas, Jeffrey Skolnick, Jianlin Cheng, Ada Sedova' : '14 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">14 more authors</span> </div> <div class="periodical"> <em>In IEEE/ACM Machine Learning with Graphs in High Performance Computing Environments (MLHPC) Workshop</em>, 2021 </div> <div class="periodical"> A collaboration between the University of Missouri, Oak Ridge National Laboratory, and beyond </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9652872" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:UebtZRa9Y70C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Computational biology is one of many scientific disciplines ripe for innovation and acceleration with the advent of high-performance computing (HPC). In recent years, the field of machine learning has also seen significant benefits from adopting HPC practices. In this work, we present a novel HPC pipeline that incorporates various machine-learning approaches for structure-based functional annotation of proteins on the scale of whole genomes. Our pipeline makes extensive use of deep learning and provides computational insights into best practices for training advanced deep-learning models for high-throughput data such as proteomics data. We showcase methodologies our pipeline currently supports and detail future tasks for our pipeline to envelop, including large-scale sequence comparison using SAdLSA and prediction of protein tertiary structures using AlphaFold2.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">AJUR</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Synthetic_Biology-480.webp 480w,/assets/img/publication_preview/Synthetic_Biology-800.webp 800w,/assets/img/publication_preview/Synthetic_Biology-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Synthetic_Biology.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Synthetic_Biology.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kouckyasynthetic" class="col-sm-8"> <div class="title">Synthetic Biology Bicistronic Designs Support Gene Expression Equally Well in vitro and in vivo</div> <div class="author"> Owen Kouckya, Jacob Wagnerb, Sofia Aguilerab, and <span class="more-authors" title="click to view 12 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '12 more authors' ? 'Benjamin Bashawb, Queena Chena, Anthony Eckdahla, Elise Edmanc, Paul Gomeza, Nick Hanlanb, Nick Kempfd, Devin Mattoon, Sam McKlin, Christopher Mazariegos, Alex Morehead, others' : '12 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">12 more authors</span> </div> <div class="periodical"> <em>AJUR</em>, 2020 </div> <div class="periodical"> Part of a collaborative NSF REU between Missouri Western State University and Davidson College </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://www.academia.edu/download/97784859/AJUR_Vol_17_Issue_1_June_2020_p13.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Synthetic biology integrates molecular biology tools and an engineering mindset to address challenges in medicine, agriculture, bioremediation, and biomanufacturing. A persistent problem in synthetic biology has been designing genetic circuits that produce predictable levels of protein. In 2013, Mutalik and colleagues developed bicistronic designs (BCDs) that make protein production more predicable in bacterial cells (in vivo). With the growing interest in producing proteins outside of cells (in vitro), we wanted to know if BCDs would work as predictably in cell-free protein synthesis (CFPS) as they do in E. coli cells. We tested 20 BCDs in CFPS and found they performed very similarly in vitro and in vivo. As a step toward developing methods for protein production in artificial cells, we also tested 3 BCDs inside nanoliter-scaled microfluidic droplets. The BCDs worked well in the microfluidic droplets, but their relative protein production levels were not as predictable as expected. These results suggest that the conditions under which gene expression happens in droplets result in a different relationship between genetic control elements such as BCDs and protein production than exists in batch CFPS or in cells.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IEEE BigData</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Gunshot_Detection-480.webp 480w,/assets/img/publication_preview/Gunshot_Detection-800.webp 800w,/assets/img/publication_preview/Gunshot_Detection-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Gunshot_Detection.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Gunshot_Detection.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="morehead_9006456" class="col-sm-8"> <div class="title">Low Cost Gunshot Detection using Deep Learning on the Raspberry Pi</div> <div class="author"> <em>Alex Morehead</em>, Lauren Ogden, Gabe Magee, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ryan Hosler, Bruce White, George Mohler' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In IEEE International Conference on Big Data</em>, 2019 </div> <div class="periodical"> Tested in real-world settings in Indianapolis, Indiana </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/abstract/document/9006456/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=IYHJU5EAAAAJ&amp;citation_for_view=IYHJU5EAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Many cities using gunshot detection technology depend on expensive systems that ultimately rely on humans differentiating between gunshots and non-gunshots, such as ShotSpotter. Thus, a scalable gunshot detection system that is low in cost and high in accuracy would be advantageous for a variety of cities across the globe, in that it would favorably promote the delegation of tasks typically worked by humans to machines. A repository of audio data was created from sound clips collected from online audio databases as well as from clips recorded using a USB microphone in residential areas and at a gun range. One-dimensional as well as two-dimensional convolutional neural networks were then trained on this sound data, and spectrograms created from this sound data, to recognize gunshots. These models were deployed to a Raspberry Pi 3 Model B+ with a short message service modem and a USB microphone attached, using a software pipeline to continuously analyze discrete two-second chunks of audio and alert a set of phone numbers if a gunshot is detected in that chunk. Testing found that a majority-rules ensemble of our one-dimensional and two-dimensional models fared best, with an accuracy above 99% on validation data as well as when distinguishing gunshots from fireworks. Besides increasing the safety standards for a city’s residents, the findings generated by this research project expand the current state of knowledge regarding sound-based applications of convolutional neural networks.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Alex C. Morehead. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-69GP935JRL"></script> <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() {
      dataLayer.push(arguments);
    }
    gtag('js', new Date());

    gtag('config', 'G-69GP935JRL');
  </script> <script defer src="/assets/js/google-analytics-setup.js?12374742c4b1801ba82226e617af7e2d"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>