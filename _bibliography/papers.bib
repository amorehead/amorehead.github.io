---
---

@inproceedings{morehead_9006456,
  author =       {Morehead, Alex and Ogden, Lauren and Magee, Gabe and Hosler,
                  Ryan and White, Bruce and Mohler, George},
  booktitle =    {IEEE International Conference on Big Data},
  title =        {Low Cost Gunshot Detection using Deep Learning on the
                  Raspberry Pi},
  year =         2019
}

@article{kouckyasynthetic,
  title =        {Synthetic Biology Bicistronic Designs Support Gene Expression
                  Equally Well in vitro and in vivo},
  author =       {Kouckya, Owen and Wagnerb, Jacob and Aguilerab, Sofia and
                  Bashawb, Benjamin and Chena, Queena and Eckdahla, Anthony and
                  Edmanc, Elise and Gomeza, Paul and Hanlanb, Nick and Kempfd,
                  Nick and Mattoon, Devin, and McKlin, Sam and Mazariegos,
                  Christopher and Morehead, Alex and others},
  journal =      {AJUR},
  year =         2020,
}

@article{Morehead_2023,
  title =        {DIPS-Plus: The enhanced database of interacting protein
                  structures for interface prediction},
  journal =      {Nature Scientific Data},
  author =       {Morehead, Alex and Chen, Chen and Sedova, Ada and Cheng,
                  Jianlin},
  year =         2023
}

@inproceedings{gao_9652872,
  author =       {Gao, Mu and Lund-Andersen, Peik and Morehead, Alex and Mahmud,
                  Sajid and Chen, Chen and Chen, Xiao and Giri, Nabin and Roy,
                  Raj S. and Quadir, Farhan and Effler, T. Chad and Prout, Ryan
                  and Abraham, Subil and Elwasif, Wael and Haas, N. Quentin and
                  Skolnick, Jeffrey and Cheng, Jianlin and Sedova, Ada},
  booktitle =    {IEEE/ACM Machine Learning with Graphs in High Performance
                  Computing Environments (MLHPC) Workshop},
  title =        {High-Performance Deep Learning Toolbox for Genome-Scale
                  Prediction of Protein Structure and Function},
  year =         2021
}

@inproceedings{
morehead2022geometric,
  title =        {Geometric Transformers for Protein Interface Contact
                  Prediction},
  author =       {Alex Morehead and Chen Chen and Jianlin Cheng},
  booktitle =    {The Tenth International Conference on Learning Representations
                  (ICLR)},
  year =         2022,
  selected =     true,
  google_scholar_id={Se3iqnhoufwC},
  html =          {https://openreview.net/forum?id=CS4463zx6Hi},
  abstract =     {Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.},
  preview =      {Geometric_Transformer.png},
  abbr =         {ICLR},
}

@article{
  morehead2024geometry,
  title =        {Geometry-Complete Perceptron Networks for 3D Molecular Graphs},
  author =       {Alex Morehead and Jianlin Cheng},
  journal =      {Bioinformatics},
  year =         2024,
  note =         {Also presented at the AAAI 2023 DLG (poster) and AI2ASE (oral presentation) workshops},
  selected =     true,
  google_scholar_id={ULOm3_A8WrAC},
  html =          {https://academic.oup.com/bioinformatics/article/40/2/btae087/7610880},
  abstract =     {Motivation: The field of geometric deep learning has recently had a profound impact on several scientific domains such as protein structure prediction and design, leading to methodological advancements within and outside of the realm of traditional machine learning. Within this spirit, in this work, we introduce GCPNET, a new chirality-aware SE(3)-equivariant graph neural network designed for representation learning of 3D biomolecular graphs. We show that GCPNET, unlike previous representation learning methods for 3D biomolecules, is widely applicable to a variety of invariant or equivariant node-level, edge-level, and graph-level tasks on biomolecular structures while being able to (1) learn important chiral properties of 3D molecules and (2) detect external force fields. Results: Across four distinct molecular-geometric tasks, we demonstrate that GCPNET’s predictions (1) for protein–ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5%, greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged mean squared error less than 0.01, more than 15% better than current methods; and (4) for molecular chirality recognition achieve a state-of-the-art prediction accuracy of 98.7%, better than any other machine learning method to date. Availability and implementation: The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/GCPNet.},
  preview =      {GCPNet.png},
  abbr =         {Bioinformatics},
}

@article{morehead2024diffusion,
  title =        {Geometry-Complete Diffusion for 3D Molecule Generation and Optimization},
  author =       {Morehead, Alex and Cheng, Jianlin},
  journal =      {Nature Communications Chemistry},
  year =         2024,
  note =         {Also presented at the ICLR 2023 MLDD workshop},
  selected =     true,
  google_scholar_id={M3ejUd6NZC8C},
  html =          {https://www.nature.com/articles/s42004-024-01233-z},
  abstract =     {Denoising diffusion probabilistic models (DDPMs) have recently taken the field of generative modeling by storm, pioneering new state-of-the-art results in disciplines such as computer vision and computational biology for diverse tasks ranging from text-guided image generation to structure-guided protein design. Along this latter line of research, methods such as those of Hoogeboom et al. 2022 have been proposed for generating 3D molecules using equivariant graph neural networks (GNNs) within a DDPM framework. Toward this end, we propose GCDM, a geometry-complete diffusion model that achieves new state-of-the-art results for 3D molecule diffusion generation by leveraging the representation learning strengths offered by GNNs that perform geometry-complete message-passing. Our results with GCDM also offer preliminary insights into how physical inductive biases impact the generative dynamics of molecular DDPMs. The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/Bio-Diffusion.},
  preview =      {GCDM.gif},
  abbr =         {CommsChem},
}

@inproceedings{morehead2023semi,
  author =       {Morehead, Alex and Chantapakul, Watchanan and Cheng, Jianlin},
  booktitle =    {IEEE International Conference on Machine Learning and
                  Applications},
  title =        {Semi-Supervised Graph Learning Meets Dimensionality Reduction},
  year =         2023,
}

@article{10.1093/bioinformatics/btad030,
  author =       {Chen, Chen and Chen, Xiao and Morehead, Alex and Wu, Tianqi
                  and Cheng, Jianlin},
  title =        {3D-equivariant graph neural networks for protein model quality
                  assessment},
  journal =      {Bioinformatics},
  year =         2023
}

@inproceedings{Shoman_2022_CVPR,
  author =       {Shoman, Maged and Aboah, Armstrong and Morehead, Alex and
                  Duan, Ye and Daud, Abdulateef and Adu-Gyamfi, Yaw},
  title =        {A Region-Based Deep Learning Approach to Automated Retail
                  Checkout},
  booktitle =    {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition (CVPR) Workshops},
  year =         2022
}

@article{morehead2022egr,
  title =        {EGR: Equivariant Graph Refinement and Assessment of 3D Protein
                  Complex Structures},
  author =       {Morehead, Alex and Chen, Xiao and Wu, Tianqi and Liu, Jian and
                  Cheng, Jianlin},
  journal =      {arXiv},
  year =         2022,
}

@article{mahmud2023accurate,
  title =        {Accurate prediction of protein tertiary structural changes
                  induced by single-site mutations with equivariant graph neural
                  networks},
  author =       {Mahmud, Sajid and Morehead, Alex and Cheng, Jianlin},
  journal =      {bioRxiv},
  year =         2023
}

@inproceedings{soltanikazemi2022drlcomplex,
  author =       {Soltanikazemi, Elham and Roy, Raj S and Quadir, Farhan and
                  Giri, Nabin and Morehead, Alex and Cheng, Jianlin},
  title =        {DRLComplex: Reconstruction of protein quaternary structures
                  using deep reinforcement learning},
  booktitle =    {International Conference on Intelligent Biology and Medicine},
  year =         2023,
}}

@article {Shanehsazzadeh2023.01.08.523187,
  author =       {Amir Shanehsazzadeh and Sharrol Bachas and Matt McPartlon and
                  George Kasun and John M. Sutton and Andrea K. Steiger and
                  Richard Shuai and Christa Kohnert and Goran Rakocevic and
                  Jahir M. Gutierrez and Chelsea Chung and Breanna K. Luton and
                  Nicolas Diaz and Simon Levine and Julian Alverio and Bailey
                  Knight and Macey Radach and Alex Morehead and Katherine
                  Bateman and David A. Spencer and Zachary McDargh and Jovan
                  Cejovic and Gaelin Kopec-Belliveau and Robel Haile and Edriss
                  Yassine and Cailen McCloskey and Monica Natividad and Dalton
                  Chapman and Joshua Bennett and Jubair Hossain and Abigail B.
                  Ventura and Gustavo M. Canales and Muttappa Gowda and Kerianne
                  A. Jackson and Jennifer T. Stanton and Marcin Ura and Luka
                  Stojanovic and Engin Yapici and Katherine Moran and Rodante
                  Caguiat and Amber Brown and Shaheed Abdulhaqq and Zheyuan Guo
                  and Lillian R. Klug and Miles Gander and Joshua Meier},
  title =        {Unlocking de novo antibody design with generative artificial
                  intelligence},
  year =         2023,
  journal =      {bioRxiv},
  note =         {Follow-up work presented at the NeurIPS 2023 MLSB workshop}
}

@inproceedings{10.1093/bioinformatics/btad203,
  title =        {A gated graph transformer for protein complex structure
                  quality assessment and its performance in CASP15},
  author =       {Chen*, Xiao and Morehead*, Alex and Liu, Jian and Cheng,
                  Jianlin},
  booktitle =    {Intelligent Systems for Molecular Biology (ISMB)},
  year =         2023,
  selected =     true,
  google_scholar_id={qxL8FJ1GzNcC},
  html =         {https://academic.oup.com/bioinformatics/article/39/Supplement_1/i308/7210460},
  abstract =     {Proteins interact to form complexes to carry out essential biological functions. Computational methods such as AlphaFold-multimer have been developed to predict the quaternary structures of protein complexes. An important yet largely unsolved challenge in protein complex structure prediction is to accurately estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. In this work, we introduce a new gated neighborhood-modulating graph transformer to predict the quality of 3D protein complex structures. It incorporates node and edge gates within a graph transformer framework to control information flow during graph message passing. We trained, evaluated and tested the method (called DProQA) on newly-curated protein complex datasets before the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) and then blindly tested it in the 2022 CASP15 experiment. The method was ranked 3rd among the single-model quality assessment methods in CASP15 in terms of the ranking loss of TM-score on 36 complex targets. The rigorous internal and external experiments demonstrate that DProQA is effective in ranking protein complex structures. The source code, data, and pre-trained models are available at https://github.com/jianlin-cheng/DProQA.},
  preview =     {Gated_Graph_Transformer.jpeg},
  abbr =        {ISMB},
}

@article{https://doi.org/10.1002/prot.26609,
  author =       {Lensink, Marc F. and Brysbaert, Guillaume and Raouraoua,
                  Nessim and Bates, Paul A. and Giulini, Marco and Honorato,
                  Rodrigo V. and van Noort, Charlotte and Teixeira, Joao M. C.
                  and Bonvin, Alexandre M. J. J. and Kong, Ren and Shi, Hang and
                  Lu, Xufeng and Chang, Shan and Liu, Jian and Guo, Zhiye and
                  Chen, Xiao and Morehead, Alex and Roy, Raj S. and Wu, Tianqi
                  and Giri, Nabin and Quadir, Farhan and Chen, Chen and Cheng,
                  Jianlin and Del Carpio, Carlos A. and Ichiishi, Eichiro and
                  Rodriguez-Lumbreras, Luis A. and Fernandez-Recio, Juan and
                  Harmalkar, Ameya and Chu, Lee-Shin and Canner, Sam and Smanta,
                  Rituparna and Gray, Jeffrey J. and Li, Hao and Lin, Peicong
                  and He, Jiahua and Tao, Huanyu and Huang, Sheng-You and
                  Roel-Touris, Jorge and Jimenez-Garcia, Brian and Christoffer,
                  Charles W. and Jain, Anika J. and Kagaya, Yuki and Kannan,
                  Harini and Nakamura, Tsukasa and Terashi, Genki and Verburgt,
                  Jacob C. and Zhang, Yuanyuan and Zhang, Zicong and Fujuta,
                  Hayato and Sekijima, Masakazu and Kihara, Daisuke and Khan,
                  Omeir and Kotelnikov, Sergei and Ghani, Usman and Padhorny,
                  Dzmitry and Beglov, Dmitri and Vajda, Sandor and Kozakov, Dima
                  and Negi, Surendra S. and Ricciardelli, Tiziana and
                  Barradas-Bautista, Didier and Cao, Zhen and Chawla, Mohit and
                  Cavallo, Luigi and Oliva, Romina and Yin, Rui and Cheung,
                  Melyssa and Guest, Johnathan D. and Lee, Jessica and Pierce,
                  Brian G. and Shor, Ben and Cohen, Tomer and Halfon, Matan and
                  Schneidman-Duhovny, Dina and Zhu, Shaowen and Yin, Rujie and
                  Sun, Yuanfei and Shen, Yang and Maszota-Zieleniak, Martyna and
                  Bojarski, Krzysztof K. and Lubecka, Emilia A. and Marcisz,
                  Mateusz and Danielsson, Annemarie and Dziadek, Lukasz and
                  Gaardlos, Margrethe and Gieldon, Artur and Liwo, Adam and
                  Samsonov, Sergey A. and Slusarz, Rafal and Zieba, Karolina and
                  Sieradzan, Adam K. and Czaplewski, Cezary and Kobayashi,
                  Shinpei and Miyakawa, Yuta and Kiyota, Yasuomi and
                  Takeda-Shitaka, Mayuko and Olechnovic, Kliment and
                  Valancauskas, Lukas and Dapkunas, Justas and Venclovas,
                  Ceslovas and Wallner, Bjorn and Yang, Lin and Hou, Chengyu and
                  He, Xiaodong and Guo, Shuai and Jiang, Shenda and Ma,
                  Xiaoliang and Duan, Rui and Qui, Liming and Xu, Xianjin and
                  Zou, Xiaoqin and Velankar, Sameer and Wodak, Shoshana J.},
  title =        {Impact of AlphaFold on structure prediction of protein
                  complexes: The CASP15-CAPRI experiment},
  journal =      {Proteins: Structure, Function, and Bioinformatics},
  year =         2023
}

@article{morehead2023gcpnet_ema,
  title =        {Protein Structure Accuracy Estimation using Geometry-Complete
                  Perceptron Networks},
  author =       {Morehead, Alex and Cheng, Jianlin},
  year =         2023,
  journal =      {Protein Science}
}

@inproceedings{
morehead2023towards,
  title =        {Towards Joint Sequence-Structure Generation of Nucleic Acid
                  and Protein Complexes},
  author =       {Morehead, Alex and Bhatnagar, Aadyot and Ruffolo, Jeffrey A.
                  and Madani, Ali},
  booktitle =    {NeurIPS Machine Learning in Structural Biology (MLSB)
                  Workshop},
  year =         2023,
  selected =     true,
  google_scholar_id={Wp0gIr-vW9MC},
  html =          {https://www.mlsb.io/papers_2023/Towards_Joint_Sequence-Structure_Generation_of_Nucleic_Acid_and_Protein_Complexes_with_SE3-Discrete_Diffusion.pdf},
  abstract =     {Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.},
  preview =      {MMDiff.png},
  abbr =         {NeurIPS MLSB},
}

@inproceedings{
jamasb2023evaluating,
  title =        {Evaluating Representation Learning on the Protein Structure
                  Universe},
  author =       {Jamasb*, Arian R., and Morehead*, Alex and Zhang*, Zuobai and
                  Joshi*, Chaitanya K. and Didi, Kieran and Mathis, Simon V. and
                  Harris, Charles and Tang, Jian and Cheng, Jianlin and Lio,
                  Pietro and Blundell, Tom L.},
  booktitle =    {The Twelth International Conference on Learning
                  Representations (ICLR)},
  note =         {Also presented at the NeurIPS 2023 MLSB workshop},
  year =         2024,
  selected =     true,
  google_scholar_id={mVmsd5A6BfQC},
  html =          {https://openreview.net/forum?id=sTYuRVrdK3},
  abstract =     {We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models. We aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.},
  preview =      {ProteinWorkshop.png},
  abbr =         {ICLR},
}

@inproceedings{
joshi2025grnade,
  title={g{RNA}de: Geometric Deep Learning for 3D {RNA} inverse design},
  author={Joshi, Chaitanya K and Jamasb, Arian R and Vi{\~n}as, Ramon
          and Harris, Charles and Mathis, Simon V and Morehead, Alex and
          Anand, Rishabh and Li{\`o}, Pietro},
  booktitle={The Thirteenth International Conference on Learning
            Representations (ICLR)},
  note={Also presented at the ICML 2023 CompBio workshop},
  year={2025},
  html={https://openreview.net/forum?id=lvw3UgeVxS},
  abbr={ICLR},
}

@inproceedings{morehead2024posebench,
  title =        {Deep Learning for Protein-Ligand Docking: Are We There Yet?},
  author =       {Morehead, Alex and Giri, Nabin and Liu, Jian and Cheng,
                  Jianlin},
  booktitle =    {ICML AI4Science Workshop},
  year =         2024,
  note =         {Selected as a spotlight presentation (top 20% - 30/159)},
  selected =     true,
  google_scholar_id={IWHjjKOFINEC},
  html =          {https://arxiv.org/abs/2405.14108},
  abstract =     {The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of docking methods within the practical context of (1) predicted (apo) protein structures, (2) multiple ligands concurrently binding to a given target protein, and (3) having no prior knowledge of binding pockets. To enable a deeper understanding of docking methods' real-world utility, we introduce PoseBench, the first comprehensive benchmark for practical protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL docking methods for apo-to-holo protein-ligand docking and protein-ligand structure generation using both single and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that all recent DL docking methods but one fail to generalize to multi-ligand protein targets and also that template-based docking algorithms perform equally well or better for multi-ligand docking as recent single-ligand DL docking methods, suggesting areas of improvement for future work. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.},
  preview =      {PoseBench.png},
  abbr =         {ICML AI4Sci},
}

@inproceedings{anand2024rna,
  title =        {RNA-FrameFlow for de novo 3D RNA Backbone Design},
  author =       {Anand*, Rishabh and Joshi*, Chaitanya K and Morehead, Alex and
                  Jamasb, Arian R and Harris, Charles and Matthis, Simon V and
                  Didi, Kieran and Hooi, Bryan, and Li{\`o}, Pietro},
  booktitle =    {ICML AI4Science \& SPIGM Workshops},
  year =         2024,
  selected =     true,
  note =         {Selected as a SPIGM (AI4Science) oral (spotlight) presentation},
  google_scholar_id={qUcmZB5y_30C},
  html =          {https://arxiv.org/abs/2406.13839},
  abstract =     {We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score >= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design},
  preview =      {RNA-FrameFlow.png},
  abbr =         {ICML AI4Sci & SPIGM},
}

@inproceedings{morehead2024flowdock,
      title={FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction}, 
      author={Alex Morehead and Jianlin Cheng},
      booktitle={Intelligent Systems for Molecular Biology (ISMB)},
      year=2025,
      note = {Presented as a CASP16 top-5 method},
      selected = true,
      google_scholar_id={hFOr9nPyWt4C},
      html={https://arxiv.org/abs/2412.10966},
      abstract = {Powerful generative models of protein-ligand structure have recently been proposed, but few of these methods support both flexible protein-ligand docking and affinity estimation. Of those that do, none can directly model multiple binding ligands concurrently or have been rigorously benchmarked on pharmacologically relevant drug targets, hindering their widespread adoption in drug discovery efforts. In this work, we propose FlowDock, a deep geometric generative model based on conditional flow matching that learns to directly map unbound (apo) structures to their bound (holo) counterparts for an arbitrary number of binding ligands. Furthermore, FlowDock provides predicted structural confidence scores and binding affinity values with each of its generated protein-ligand complex structures, enabling fast virtual screening of new (multi-ligand) drug targets. For the commonly-used PoseBusters Benchmark dataset, FlowDock achieves a 51% blind docking success rate using unbound (apo) protein input structures and without any information derived from multiple sequence alignments, and for the challenging new DockGen-E dataset, FlowDock matches the performance of single-sequence Chai-1 for binding pocket generalization. Additionally, in the ligand category of the 16th community-wide Critical Assessment of Techniques for Structure Prediction (CASP16), FlowDock ranked among the top-5 methods for pharmacological binding affinity estimation across 140 protein-ligand complexes, demonstrating the efficacy of its learned representations in virtual screening. Source code, data, and pre-trained models are available at https://github.com/BioinfoMachineLearning/FlowDock.},
      preview = {FlowDock.gif},
      abbr = {ISMB},
}

@inproceedings{morehead2025multicom,
  title =        {Protein-ligand structure and affinity prediction in CASP16
                  using a geometric deep learning ensemble and flow matching},
  author =       {Morehead, Alex and Liu, Jian and Neupane, Pawan and
                  Giri, Nabin, and Cheng, Jianlin},
  booktitle =    {CASP16 Abstracts},
  note =         {Presented as a CASP16 top-5 method},
  year =         2025,
}
