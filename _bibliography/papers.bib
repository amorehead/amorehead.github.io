---
---

% 2019 papers:
@inproceedings{morehead_9006456,
  author =       {Morehead, Alex and Ogden, Lauren and Magee, Gabe and Hosler,
                  Ryan and White, Bruce and Mohler, George},
  booktitle =    {IEEE International Conference on Big Data},
  title =        {Low Cost Gunshot Detection using Deep Learning on the
                  Raspberry Pi},
  year =         2019,
  note = {Tested in real-world settings in Indianpolis, Indiana},
  google_scholar_id={9yKSN-GCB0IC},
  html =         {https://ieeexplore.ieee.org/abstract/document/9006456/},
  abstract = {Many cities using gunshot detection technology depend on expensive systems that ultimately rely on humans differentiating between gunshots and non-gunshots, such as ShotSpotter. Thus, a scalable gunshot detection system that is low in cost and high in accuracy would be advantageous for a variety of cities across the globe, in that it would favorably promote the delegation of tasks typically worked by humans to machines. A repository of audio data was created from sound clips collected from online audio databases as well as from clips recorded using a USB microphone in residential areas and at a gun range. One-dimensional as well as two-dimensional convolutional neural networks were then trained on this sound data, and spectrograms created from this sound data, to recognize gunshots. These models were deployed to a Raspberry Pi 3 Model B+ with a short message service modem and a USB microphone attached, using a software pipeline to continuously analyze discrete two-second chunks of audio and alert a set of phone numbers if a gunshot is detected in that chunk. Testing found that a majority-rules ensemble of our one-dimensional and two-dimensional models fared best, with an accuracy above 99% on validation data as well as when distinguishing gunshots from fireworks. Besides increasing the safety standards for a city's residents, the findings generated by this research project expand the current state of knowledge regarding sound-based applications of convolutional neural networks.},
  preview=      {Gunshot_Detection.gif},
  abbr =         {IEEE BigData},
}

% 2020 papers:
@article{kouckyasynthetic,
  title =        {Synthetic Biology Bicistronic Designs Support Gene Expression
                  Equally Well in vitro and in vivo},
  author =       {Kouckya, Owen and Wagnerb, Jacob and Aguilerab, Sofia and
                  Bashawb, Benjamin and Chena, Queena and Eckdahla, Anthony and
                  Edmanc, Elise and Gomeza, Paul and Hanlanb, Nick and Kempfd,
                  Nick and Mattoon, Devin, and McKlin, Sam and Mazariegos,
                  Christopher and Morehead, Alex and others},
  journal =      {AJUR},
  year =         2020,
  note=         {Part of a collaborative NSF REU between Missouri Western State University and Davidson College},
  google_scholar_id={2osOgNQ5qMEC},
  html =         {https://www.academia.edu/download/97784859/AJUR_Vol_17_Issue_1_June_2020_p13.pdf},
  abstract={Synthetic biology integrates molecular biology tools and an engineering mindset to address challenges in medicine, agriculture, bioremediation, and biomanufacturing. A persistent problem in synthetic biology has been designing genetic circuits that produce predictable levels of protein. In 2013, Mutalik and colleagues developed bicistronic designs (BCDs) that make protein production more predicable in bacterial cells (in vivo). With the growing interest in producing proteins outside of cells (in vitro), we wanted to know if BCDs would work as predictably in cell-free protein synthesis (CFPS) as they do in E. coli cells. We tested 20 BCDs in CFPS and found they performed very similarly in vitro and in vivo. As a step toward developing methods for protein production in artificial cells, we also tested 3 BCDs inside nanoliter-scaled microfluidic droplets. The BCDs worked well in the microfluidic droplets, but their relative protein production levels were not as predictable as expected. These results suggest that the conditions under which gene expression happens in droplets result in a different relationship between genetic control elements such as BCDs and protein production than exists in batch CFPS or in cells.},
  preview =      {Synthetic_Biology.png},
  abbr =         {AJUR},
}

% 2021 papers:
@inproceedings{gao_9652872,
  author =       {Gao, Mu and Lund-Andersen, Peik and Morehead, Alex and Mahmud,
                  Sajid and Chen, Chen and Chen, Xiao and Giri, Nabin and Roy,
                  Raj S. and Quadir, Farhan and Effler, T. Chad and Prout, Ryan
                  and Abraham, Subil and Elwasif, Wael and Haas, N. Quentin and
                  Skolnick, Jeffrey and Cheng, Jianlin and Sedova, Ada},
  booktitle =    {IEEE/ACM Machine Learning with Graphs in High Performance
                  Computing Environments (MLHPC) Workshop},
  title =        {High-Performance Deep Learning Toolbox for Genome-Scale
                  Prediction of Protein Structure and Function},
  year =         2021,
  note =         {A collaboration between the University of Missouri, Oak Ridge National Laboratory, and beyond},
  google_scholar_id={UebtZRa9Y70C},
  html =         {https://ieeexplore.ieee.org/abstract/document/9652872},
  abstract={Computational biology is one of many scientific disciplines ripe for innovation and acceleration with the advent of high-performance computing (HPC). In recent years, the field of machine learning has also seen significant benefits from adopting HPC practices. In this work, we present a novel HPC pipeline that incorporates various machine-learning approaches for structure-based functional annotation of proteins on the scale of whole genomes. Our pipeline makes extensive use of deep learning and provides computational insights into best practices for training advanced deep-learning models for high-throughput data such as proteomics data. We showcase methodologies our pipeline currently supports and detail future tasks for our pipeline to envelop, including large-scale sequence comparison using SAdLSA and prediction of protein tertiary structures using AlphaFold2.},
  preview =      {Genome-Scale_Protein_Structure.gif},
  abbr =         {MLHPC},
}

% 2022 papers:
@inproceedings{morehead2022geometric,
  title =        {Geometric Transformers for Protein Interface Contact
                  Prediction},
  author =       {Alex Morehead and Chen Chen and Jianlin Cheng},
  booktitle =    {The Tenth International Conference on Learning Representations
                  (ICLR)},
  year =         2022,
  note =         {Presented a new line graph message passing transformer at ICLR 2022},
  selected =     true,
  google_scholar_id={Se3iqnhoufwC},
  html =          {https://openreview.net/forum?id=CS4463zx6Hi},
  abstract =     {Computational methods for predicting the interface contacts between proteins come highly sought after for drug discovery as they can significantly advance the accuracy of alternative approaches, such as protein-protein docking, protein function analysis tools, and other computational methods for protein bioinformatics. In this work, we present the Geometric Transformer, a novel geometry-evolving graph transformer for rotation and translation-invariant protein interface contact prediction, packaged within DeepInteract, an end-to-end prediction pipeline. DeepInteract predicts partner-specific protein interface contacts (i.e., inter-protein residue-residue contacts) given the 3D tertiary structures of two proteins as input. In rigorous benchmarks, DeepInteract, on challenging protein complex targets from the 13th and 14th CASP-CAPRI experiments as well as Docking Benchmark 5, achieves 14% and 1.1% top L/5 precision (L: length of a protein unit in a complex), respectively. In doing so, DeepInteract, with the Geometric Transformer as its graph-based backbone, outperforms existing methods for interface contact prediction in addition to other graph-based neural network backbones compatible with DeepInteract, thereby validating the effectiveness of the Geometric Transformer for learning rich relational-geometric features for downstream tasks on 3D protein structures.},
  preview =      {Geometric_Transformer.png},
  abbr =         {ICLR},
}

@article{morehead2022egr,
  title =        {EGR: Equivariant Graph Refinement and Assessment of 3D Protein
                  Complex Structures},
  author =       {Morehead, Alex and Chen, Xiao and Wu, Tianqi and Liu, Jian and
                  Cheng, Jianlin},
  journal =      {arXiv},
  year =         2022,
  note={First deep learning method for joint protein-ligand complex structure quality assessment and refinement},
  google_scholar_id={KlAtU1dfN6UC},
  html =         {https://arxiv.org/abs/2205.10390},
  abstract={Protein complexes are macromolecules essential to the functioning and well-being of all living organisms. As the structure of a protein complex, in particular its region of interaction between multiple protein subunits (i.e., chains), has a notable influence on the biological function of the complex, computational methods that can quickly and effectively be used to refine and assess the quality of a protein complex's 3D structure can directly be used within a drug discovery pipeline to accelerate the development of new therapeutics and improve the efficacy of future vaccines. In this work, we introduce the Equivariant Graph Refiner (EGR), a novel E(3)-equivariant graph neural network (GNN) for multi-task structure refinement and assessment of protein complexes. Our experiments on new, diverse protein complex datasets, all of which we make publicly available in this work, demonstrate the state-of-the-art effectiveness of EGR for atomistic refinement and assessment of protein complexes and outline directions for future work in the field. In doing so, we establish a baseline for future studies in macromolecular refinement and structure analysis.},
  preview =      {EGR.png},
  abbr =         {arXiv},
}

@inproceedings{Shoman_2022_CVPR,
  author =       {Shoman, Maged and Aboah, Armstrong and Morehead, Alex and
                  Duan, Ye and Daud, Abdulateef and Adu-Gyamfi, Yaw},
  title =        {A Region-Based Deep Learning Approach to Automated Retail
                  Checkout},
  booktitle =    {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition (CVPR) Workshops},
  year =         2022,
  note =         {Instilling computer vision networks with industrial inductive biases for automated retail checkout},
  google_scholar_id={MXK_kJrjxJIC},
  html =         {https://openaccess.thecvf.com/content/CVPR2022W/AICity/html/Shoman_A_Region-Based_Deep_Learning_Approach_to_Automated_Retail_Checkout_CVPRW_2022_paper.html},
  abstract={Automating the product checkout process at conventional retail stores is a task poised to have large impacts on society generally speaking. Towards this end, reliable deep learning models that enable automated product counting for fast customer checkout can make this goal a reality. In this work, we propose a novel, region-based deep learning approach to automate product counting using a customized YOLOv5 object detection pipeline and the DeepSORT algorithm. Our results on challenging, real-world test videos demonstrate that our method can generalize its predictions to a sufficient level of accuracy and with a fast enough runtime to warrant deployment to real-world commercial settings. Our proposed method won 4th place in the 2022 AI City Challenge, Track 4, with an F1 score of 0.4400 on experimental validation data.},
  preview =      {Automated_Retail_Checkout.png},
  abbr =         {CVPR},
}

% 2023 papers:
@article{https://doi.org/10.1002/prot.26609,
  author =       {Lensink, Marc F. and Brysbaert, Guillaume and Raouraoua,
                  Nessim and Bates, Paul A. and Giulini, Marco and Honorato,
                  Rodrigo V. and van Noort, Charlotte and Teixeira, Joao M. C.
                  and Bonvin, Alexandre M. J. J. and Kong, Ren and Shi, Hang and
                  Lu, Xufeng and Chang, Shan and Liu, Jian and Guo, Zhiye and
                  Chen, Xiao and Morehead, Alex and Roy, Raj S. and Wu, Tianqi
                  and Giri, Nabin and Quadir, Farhan and Chen, Chen and Cheng,
                  Jianlin and Del Carpio, Carlos A. and Ichiishi, Eichiro and
                  Rodriguez-Lumbreras, Luis A. and Fernandez-Recio, Juan and
                  Harmalkar, Ameya and Chu, Lee-Shin and Canner, Sam and Smanta,
                  Rituparna and Gray, Jeffrey J. and Li, Hao and Lin, Peicong
                  and He, Jiahua and Tao, Huanyu and Huang, Sheng-You and
                  Roel-Touris, Jorge and Jimenez-Garcia, Brian and Christoffer,
                  Charles W. and Jain, Anika J. and Kagaya, Yuki and Kannan,
                  Harini and Nakamura, Tsukasa and Terashi, Genki and Verburgt,
                  Jacob C. and Zhang, Yuanyuan and Zhang, Zicong and Fujuta,
                  Hayato and Sekijima, Masakazu and Kihara, Daisuke and Khan,
                  Omeir and Kotelnikov, Sergei and Ghani, Usman and Padhorny,
                  Dzmitry and Beglov, Dmitri and Vajda, Sandor and Kozakov, Dima
                  and Negi, Surendra S. and Ricciardelli, Tiziana and
                  Barradas-Bautista, Didier and Cao, Zhen and Chawla, Mohit and
                  Cavallo, Luigi and Oliva, Romina and Yin, Rui and Cheung,
                  Melyssa and Guest, Johnathan D. and Lee, Jessica and Pierce,
                  Brian G. and Shor, Ben and Cohen, Tomer and Halfon, Matan and
                  Schneidman-Duhovny, Dina and Zhu, Shaowen and Yin, Rujie and
                  Sun, Yuanfei and Shen, Yang and Maszota-Zieleniak, Martyna and
                  Bojarski, Krzysztof K. and Lubecka, Emilia A. and Marcisz,
                  Mateusz and Danielsson, Annemarie and Dziadek, Lukasz and
                  Gaardlos, Margrethe and Gieldon, Artur and Liwo, Adam and
                  Samsonov, Sergey A. and Slusarz, Rafal and Zieba, Karolina and
                  Sieradzan, Adam K. and Czaplewski, Cezary and Kobayashi,
                  Shinpei and Miyakawa, Yuta and Kiyota, Yasuomi and
                  Takeda-Shitaka, Mayuko and Olechnovic, Kliment and
                  Valancauskas, Lukas and Dapkunas, Justas and Venclovas,
                  Ceslovas and Wallner, Bjorn and Yang, Lin and Hou, Chengyu and
                  He, Xiaodong and Guo, Shuai and Jiang, Shenda and Ma,
                  Xiaoliang and Duan, Rui and Qui, Liming and Xu, Xianjin and
                  Zou, Xiaoqin and Velankar, Sameer and Wodak, Shoshana J.},
  title =        {Impact of AlphaFold on structure prediction of protein
                  complexes: The CASP15-CAPRI experiment},
  journal =      {Proteins: Structure, Function, and Bioinformatics},
  year =         2023,
  note={Analysis of the CASP15-CAPRI experiment's results},
  google_scholar_id={aqlVkmm33-oC},
  html =         {https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.26609},
  abstract={We present the results for CAPRI Round 54, the 5th joint CASP-CAPRI protein assembly prediction challenge. The Round offered 37 targets, including 14 homodimers, 3 homo-trimers, 13 heterodimers including 3 antibody–antigen complexes, and 7 large assemblies. On average ~70 CASP and CAPRI predictor groups, including more than 20 automatics servers, submitted models for each target. A total of 21 941 models submitted by these groups and by 15 CAPRI scorer groups were evaluated using the CAPRI model quality measures and the DockQ score consolidating these measures. The prediction performance was quantified by a weighted score based on the number of models of acceptable quality or higher submitted by each group among their five best models. Results show substantial progress achieved across a significant fraction of the 60+ participating groups. High-quality models were produced for about 40% of the targets compared to 8% two years earlier. This remarkable improvement is due to the wide use of the AlphaFold2 and AlphaFold2-Multimer software and the confidence metrics they provide. Notably, expanded sampling of candidate solutions by manipulating these deep learning inference engines, enriching multiple sequence alignments, or integration of advanced modeling tools, enabled top performing groups to exceed the performance of a standard AlphaFold2-Multimer version used as a yard stick. This notwithstanding, performance remained poor for complexes with antibodies and nanobodies, where evolutionary relationships between the binding partners are lacking, and for complexes featuring conformational flexibility, clearly indicating that the prediction of protein complexes remains a challenging problem.},
  preview =      {CASP15-CAPRI.png},
  abbr =         {CASP15},
}

@inproceedings{10.1093/bioinformatics/btad203,
  title =        {A gated graph transformer for protein complex structure
                  quality assessment and its performance in CASP15},
  author =       {Chen*, Xiao and Morehead*, Alex and Liu, Jian and Cheng,
                  Jianlin},
  booktitle =    {Intelligent Systems for Molecular Biology (ISMB)},
  year =         2023,
  note =         {Follow-up work to Geometric Transformers, presented at ISMB 2023},
  selected =     true,
  google_scholar_id={qxL8FJ1GzNcC},
  html =         {https://academic.oup.com/bioinformatics/article/39/Supplement_1/i308/7210460},
  abstract =     {Proteins interact to form complexes to carry out essential biological functions. Computational methods such as AlphaFold-multimer have been developed to predict the quaternary structures of protein complexes. An important yet largely unsolved challenge in protein complex structure prediction is to accurately estimate the quality of predicted protein complex structures without any knowledge of the corresponding native structures. Such estimations can then be used to select high-quality predicted complex structures to facilitate biomedical research such as protein function analysis and drug discovery. In this work, we introduce a new gated neighborhood-modulating graph transformer to predict the quality of 3D protein complex structures. It incorporates node and edge gates within a graph transformer framework to control information flow during graph message passing. We trained, evaluated and tested the method (called DProQA) on newly-curated protein complex datasets before the 15th Critical Assessment of Techniques for Protein Structure Prediction (CASP15) and then blindly tested it in the 2022 CASP15 experiment. The method was ranked 3rd among the single-model quality assessment methods in CASP15 in terms of the ranking loss of TM-score on 36 complex targets. The rigorous internal and external experiments demonstrate that DProQA is effective in ranking protein complex structures. The source code, data, and pre-trained models are available at https://github.com/jianlin-cheng/DProQA.},
  preview =     {Gated_Graph_Transformer.jpeg},
  abbr =        {ISMB},
}

@inproceedings{morehead2023towards,
  title =        {Towards Joint Sequence-Structure Generation of Nucleic Acid
                  and Protein Complexes},
  author =       {Morehead, Alex and Bhatnagar, Aadyot and Ruffolo, Jeffrey A.
                  and Madani, Ali},
  booktitle =    {NeurIPS Machine Learning in Structural Biology (MLSB)
                  Workshop},
  year =         2023,
  note =         {First generative model of protein and nucleic acid biomolecules},
  selected =     true,
  google_scholar_id={Wp0gIr-vW9MC},
  html =          {https://www.mlsb.io/papers_2023/Towards_Joint_Sequence-Structure_Generation_of_Nucleic_Acid_and_Protein_Complexes_with_SE3-Discrete_Diffusion.pdf},
  abstract =     {Generative models of macromolecules carry abundant and impactful implications for industrial and biomedical efforts in protein engineering. However, existing methods are currently limited to modeling protein structures or sequences, independently or jointly, without regard to the interactions that commonly occur between proteins and other macromolecules. In this work, we introduce MMDiff, a generative model that jointly designs sequences and structures of nucleic acid and protein complexes, independently or in complex, using joint SE(3)-discrete diffusion noise. Such a model has important implications for emerging areas of macromolecular design including structure-based transcription factor design and design of noncoding RNA sequences. We demonstrate the utility of MMDiff through a rigorous new design benchmark for macromolecular complex generation that we introduce in this work. Our results demonstrate that MMDiff is able to successfully generate micro-RNA and single-stranded DNA molecules while being modestly capable of joint modeling DNA and RNA molecules in interaction with multi-chain protein complexes. Source code: https://github.com/Profluent-Internships/MMDiff.},
  preview =      {MMDiff.png},
  abbr =         {NeurIPS MLSB},
}

@article{Morehead_2023,
  title =        {DIPS-Plus: The enhanced database of interacting protein
                  structures for interface prediction},
  journal =      {Nature Scientific Data},
  author =       {Morehead, Alex and Chen, Chen and Sedova, Ada and Cheng,
                  Jianlin},
  year =         2023,
  note={At release, the largest annotated dataset of protein-protein structural interactions for machine learning},
  google_scholar_id={roLk4NBRz8UC},
  html =         {https://www.nature.com/articles/s41597-023-02409-3},
  abstract={In this work, we expand on a dataset recently introduced for protein interface prediction (PIP), the Database of Interacting Protein Structures (DIPS), to present DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for machine learning of protein interfaces. While the original DIPS dataset contains only the Cartesian coordinates for atoms contained in the protein complex along with their types, DIPS-Plus contains multiple residue-level features including surface proximities, half-sphere amino acid compositions, and new profile hidden Markov model (HMM)-based sequence features for each amino acid, providing researchers a curated feature bank for training protein interface prediction methods. We demonstrate through rigorous benchmarks that training an existing state-of-the-art (SOTA) model for PIP on DIPS-Plus yields new SOTA results, surpassing the performance of some of the latest models trained on residue-level and atom-level encodings of protein complexes to date.},
  preview =      {DIPS-Plus.webp},
  abbr =         {Scientific Data},
}

@inproceedings{morehead2023semi,
  author =       {Morehead, Alex and Chantapakul, Watchanan and Cheng, Jianlin},
  booktitle =    {IEEE International Conference on Machine Learning and
                  Applications},
  title =        {Semi-Supervised Graph Learning Meets Dimensionality Reduction},
  year =         2023,
  note =         {First characterization of the interplay between dimensionality reduction and semi-supervised graph deep learning},
  google_scholar_id={5nxA0vEk-isC},
  html =         {https://ieeexplore.ieee.org/abstract/document/10460069/},
  abstract={Semi-supervised learning (SSL) has recently received increased attention from machine learning researchers. By enabling effective propagation of known labels in graph-based deep learning (GDL) algorithms, SSL is poised to become an increasingly used technique in GDL in the coming years. However, there are currently few explorations in the graph-based SSL literature on exploiting classical dimensionality reduction techniques for improved label propagation. In this work, we investigate the use of dimensionality reduction techniques such as PCA, t-SNE, and UMAP to see their effect on the performance of graph neural networks (GNNs) designed for semi-supervised propagation of node labels. Our study makes use of benchmark semi-supervised GDL datasets such as the Cora and Citeseer datasets to allow meaningful comparisons of the representations learned by each algorithm when paired with a dimensionality reduction technique. Our comprehensive benchmarks and clus-tering visualizations quantitatively and qualitatively demonstrate that, under certain conditions, employing a priori and a posteriori dimensionality reduction to GNN inputs and outputs, respectively, can simultaneously improve the effectiveness of semi-supervised node label propagation and node clustering. Our source code is freely available on GitHub.},
  preview =      {SSL_with_GNNs_and_DR.gif},
  abbr =         {ICMLA},
}

@article{10.1093/bioinformatics/btad030,
  author =       {Chen, Chen and Chen, Xiao and Morehead, Alex and Wu, Tianqi
                  and Cheng, Jianlin},
  title =        {3D-equivariant graph neural networks for protein model quality
                  assessment},
  journal =      {Bioinformatics},
  year =         2023,
  note =         {Follow-up to Geometric Transformers introducing line graph message passing to equivariant graph neural networks},
  google_scholar_id={8k81kl-MbHgC},
  html =         {https://academic.oup.com/bioinformatics/article-abstract/39/1/btad030/6986970},
  abstract={Quality assessment (QA) of predicted protein tertiary structure models plays an important role in ranking and using them. With the recent development of deep learning end-to-end protein structure prediction techniques for generating highly confident tertiary structures for most proteins, it is important to explore corresponding QA strategies to evaluate and select the structural models predicted by them since these models have better quality and different properties than the models predicted by traditional tertiary structure prediction methods. We develop EnQA, a novel graph-based 3D-equivariant neural network method that is equivariant to rotation and translation of 3D objects to estimate the accuracy of protein structural models by leveraging the structural features acquired from the state-of-the-art tertiary structure prediction method—AlphaFold2. We train and test the method on both traditional model datasets (e.g. the datasets of the Critical Assessment of Techniques for Protein Structure Prediction) and a new dataset of high-quality structural models predicted only by AlphaFold2 for the proteins whose experimental structures were released recently. Our approach achieves state-of-the-art performance on protein structural models predicted by both traditional protein structure prediction methods and the latest end-to-end deep learning method—AlphaFold2. It performs even better than the model QA scores provided by AlphaFold2 itself. The results illustrate that the 3D-equivariant graph neural network is a promising approach to the evaluation of protein structural models. Integrating AlphaFold2 features with other complementary sequence and structural features is important for improving protein model QA. The source code is available at https://github.com/BioinfoMachineLearning/EnQA.},
  preview =      {EnQA.jpeg},
  abbr =         {Bioinformatics},
}

@article{mahmud2023accurate,
  title =        {Accurate prediction of protein tertiary structural changes
                  induced by single-site mutations with equivariant graph neural
                  networks},
  author =       {Mahmud, Sajid and Morehead, Alex and Cheng, Jianlin},
  journal =      {bioRxiv},
  year =         2023,
  note =         {First deep learning method to model single-site structural changes in proteins},
  google_scholar_id={4DMP91E08xMC},
  html =         {https://www.biorxiv.org/content/10.1101/2023.10.03.560758.abstract},
  abstract =     {Predicting the change of protein tertiary structure caused by singlesite mutations is important for studying protein structure, function, and interaction. Even though computational protein structure prediction methods such as AlphaFold can predict the overall tertiary structures of most proteins rather accurately, they are not sensitive enough to accurately predict the structural changes induced by single-site amino acid mutations on proteins. Specialized mutation prediction methods mostly focus on predicting the overall stability or function changes caused by mutations without attempting to predict the exact mutation-induced structural changes, limiting their use in protein mutation study. In this work, we develop the first deep learning method based on equivariant graph neural networks (EGNN) to directly predict the tertiary structural changes caused by single-site mutations and the tertiary structure of any protein mutant from the structure of its wild-type counterpart. The results show that it performs substantially better in predicting the tertiary structures of protein mutants than the widely used protein structure prediction method AlphaFold.},
  preview =      {Geometric_Mutation_Prediction.png},
  abbr =         {bioRxiv},
}

@inproceedings{soltanikazemi2023drlcomplex,
  author =       {Soltanikazemi, Elham and Roy, Raj S and Quadir, Farhan and
                  Giri, Nabin and Morehead, Alex and Cheng, Jianlin},
  title =        {DRLComplex: Reconstruction of protein quaternary structures
                  using deep reinforcement learning},
  booktitle =    {International Conference on Intelligent Biology and Medicine},
  year =         2023,
  note =         {First deep Q-learning algorithm for protein complex structure modeling},
  google_scholar_id={Zph67rFs4hoC},
  html =         {https://arxiv.org/abs/2205.13594},
  abstract =     {Predicted inter-chain residue-residue contacts can be used to build the quaternary structure of protein complexes from scratch. However, only a small number of methods have been developed to reconstruct protein quaternary structures using predicted inter-chain contacts. Here, we present an agent-based self-learning method based on deep reinforcement learning (DRLComplex) to build protein complex structures using inter-chain contacts as distance constraints. We rigorously tested DRLComplex on two standard datasets of homodimeric and heterodimeric protein complexes (i.e., the CASP-CAPRI homodimer and Std_32 heterodimer datasets) using both true and predicted interchain contacts as inputs. Utilizing true contacts as input, DRLComplex achieved high average TM-scores of 0.9895 and 0.9881 and a low average interface RMSD (I_RMSD) of 0.2197 and 0.92 on the two datasets, respectively. When predicted contacts are used, the method achieves TM-scores of 0.73 and 0.76 for homodimers and heterodimers, respectively. Our experiments find that the accuracy of reconstructed quaternary structures depends on the accuracy of the contact predictions. Compared to other optimization methods for reconstructing quaternary structures from inter-chain contacts, DRLComplex performs similar to an advanced gradient descent method and better than a Markov Chain Monte Carlo simulation method and a simulated annealing-based method, validating the effectiveness of DRLComplex for quaternary reconstruction of protein complexes.},
  preview =      {DRLComplex.png},
  abbr =         {ICIBM},
}

@article {Shanehsazzadeh2023.01.08.523187,
  author =       {Amir Shanehsazzadeh and Sharrol Bachas and Matt McPartlon and
                  George Kasun and John M. Sutton and Andrea K. Steiger and
                  Richard Shuai and Christa Kohnert and Goran Rakocevic and
                  Jahir M. Gutierrez and Chelsea Chung and Breanna K. Luton and
                  Nicolas Diaz and Simon Levine and Julian Alverio and Bailey
                  Knight and Macey Radach and Alex Morehead and Katherine
                  Bateman and David A. Spencer and Zachary McDargh and Jovan
                  Cejovic and Gaelin Kopec-Belliveau and Robel Haile and Edriss
                  Yassine and Cailen McCloskey and Monica Natividad and Dalton
                  Chapman and Joshua Bennett and Jubair Hossain and Abigail B.
                  Ventura and Gustavo M. Canales and Muttappa Gowda and Kerianne
                  A. Jackson and Jennifer T. Stanton and Marcin Ura and Luka
                  Stojanovic and Engin Yapici and Katherine Moran and Rodante
                  Caguiat and Amber Brown and Shaheed Abdulhaqq and Zheyuan Guo
                  and Lillian R. Klug and Miles Gander and Joshua Meier},
  title =        {Unlocking de novo antibody design with generative artificial
                  intelligence},
  year =         2023,
  journal =      {bioRxiv},
  note =         {Follow-up work presented at the NeurIPS 2023 MLSB workshop},
  google_scholar_id={4TOpqqG69KYC},
  html =         {https://www.biorxiv.org/content/10.1101/2023.01.08.523187.abstract},
  abstract =     {Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of ~106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with ~3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.},
  preview =      {Antibody_Design_with_Generative_AI.png},
  abbr =         {bioRxiv},
}

% 2024 papers:
@article{morehead2024geometry,
  title =        {Geometry-Complete Perceptron Networks for 3D Molecular Graphs},
  author =       {Alex Morehead and Jianlin Cheng},
  journal =      {Bioinformatics},
  year =         2024,
  note =         {Also presented at the AAAI 2023 DLG (poster) and AI2ASE (oral presentation) workshops},
  selected =     true,
  google_scholar_id={ULOm3_A8WrAC},
  html =          {https://academic.oup.com/bioinformatics/article/40/2/btae087/7610880},
  abstract =     {Motivation: The field of geometric deep learning has recently had a profound impact on several scientific domains such as protein structure prediction and design, leading to methodological advancements within and outside of the realm of traditional machine learning. Within this spirit, in this work, we introduce GCPNET, a new chirality-aware SE(3)-equivariant graph neural network designed for representation learning of 3D biomolecular graphs. We show that GCPNET, unlike previous representation learning methods for 3D biomolecules, is widely applicable to a variety of invariant or equivariant node-level, edge-level, and graph-level tasks on biomolecular structures while being able to (1) learn important chiral properties of 3D molecules and (2) detect external force fields. Results: Across four distinct molecular-geometric tasks, we demonstrate that GCPNET’s predictions (1) for protein–ligand binding affinity achieve a statistically significant correlation of 0.608, more than 5%, greater than current state-of-the-art methods; (2) for protein structure ranking achieve statistically significant target-local and dataset-global correlations of 0.616 and 0.871, respectively; (3) for Newtownian many-body systems modeling achieve a task-averaged mean squared error less than 0.01, more than 15% better than current methods; and (4) for molecular chirality recognition achieve a state-of-the-art prediction accuracy of 98.7%, better than any other machine learning method to date. Availability and implementation: The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/GCPNet.},
  preview =      {GCPNet.png},
  abbr =         {Bioinformatics},
}

@article{morehead2024diffusion,
  title =        {Geometry-Complete Diffusion for 3D Molecule Generation and Optimization},
  author =       {Morehead, Alex and Cheng, Jianlin},
  journal =      {Nature Communications Chemistry},
  year =         2024,
  note =         {Also presented at the ICLR 2023 MLDD workshop},
  selected =     true,
  google_scholar_id={M3ejUd6NZC8C},
  html =          {https://www.nature.com/articles/s42004-024-01233-z},
  abstract =     {Denoising diffusion probabilistic models (DDPMs) have recently taken the field of generative modeling by storm, pioneering new state-of-the-art results in disciplines such as computer vision and computational biology for diverse tasks ranging from text-guided image generation to structure-guided protein design. Along this latter line of research, methods such as those of Hoogeboom et al. 2022 have been proposed for generating 3D molecules using equivariant graph neural networks (GNNs) within a DDPM framework. Toward this end, we propose GCDM, a geometry-complete diffusion model that achieves new state-of-the-art results for 3D molecule diffusion generation by leveraging the representation learning strengths offered by GNNs that perform geometry-complete message-passing. Our results with GCDM also offer preliminary insights into how physical inductive biases impact the generative dynamics of molecular DDPMs. The source code, data, and instructions to train new models or reproduce our results are freely available at https://github.com/BioinfoMachineLearning/Bio-Diffusion.},
  preview =      {GCDM.gif},
  abbr =         {CommsChem},
}

@article{morehead2024gcpnet_ema,
  title =        {Protein Structure Accuracy Estimation using Geometry-Complete
                  Perceptron Networks},
  author =       {Morehead, Alex and Cheng, Jianlin},
  year =         2024,
  journal =      {Protein Science},
  note =         {Follow-up work with GCPNet for fast protein structure accuracy estimation},
  google_scholar_id={9ZlFYXVOiuMC},
  html =          {https://onlinelibrary.wiley.com/doi/abs/10.1002/pro.4932},
  abstract={Estimating the accuracy of protein structural models is a critical task in protein bioinformatics. The need for robust methods in the estimation of protein model accuracy (EMA) is prevalent in the field of protein structure prediction, where computationally-predicted structures need to be screened rapidly for the reliability of the positions predicted for each of their amino acid residues and their overall quality. Current methods proposed for EMA are either coupled tightly to existing protein structure prediction methods or evaluate protein structures without sufficiently leveraging the rich, geometric information available in such structures to guide accuracy estimation. In this work, we propose a geometric message passing neural network referred to as the geometry-complete perceptron network for protein structure EMA (GCPNet-EMA), where we demonstrate through rigorous computational benchmarks that GCPNet-EMA's accuracy estimations are 47% faster and more than 10% (6%) more correlated with ground-truth measures of per-residue (per-target) structural accuracy compared to baseline state-of-the-art methods for tertiary (multimer) structure EMA including AlphaFold 2. The source code and data for GCPNet-EMA are available on GitHub, and a public web server implementation is freely available.},
  preview =      {GCPNet-EMA.jpg},
  abbr =         {Protein Science},
}

@inproceedings{jamasb2024evaluating,
  title =        {Evaluating Representation Learning on the Protein Structure
                  Universe},
  author =       {Jamasb*, Arian R., and Morehead*, Alex and Joshi*, Chaitanya K.
                  and Zhang*, Zuobai and Didi, Kieran and Mathis, Simon V. and
                  Harris, Charles and Tang, Jian and Cheng, Jianlin and Lio,
                  Pietro and Blundell, Tom L.},
  booktitle =    {The Twelth International Conference on Learning
                  Representations (ICLR)},
  note =         {Also presented at the NeurIPS 2023 MLSB workshop},
  year =         2024,
  selected =     true,
  google_scholar_id={mVmsd5A6BfQC},
  html =          {https://openreview.net/forum?id=sTYuRVrdK3},
  abstract =     {We introduce ProteinWorkshop, a comprehensive benchmark suite for representation learning on protein structures with Geometric Graph Neural Networks. We consider large-scale pre-training and downstream tasks on both experimental and predicted structures to enable the systematic evaluation of the quality of the learned structural representation and their usefulness in capturing functional relationships for downstream tasks. We find that: (1) large-scale pretraining on AlphaFold structures and auxiliary tasks consistently improve the performance of both rotation-invariant and equivariant GNNs, and (2) more expressive equivariant GNNs benefit from pretraining to a greater extent compared to invariant models. We aim to establish a common ground for the machine learning and computational biology communities to rigorously compare and advance protein structure representation learning. Our open-source codebase reduces the barrier to entry for working with large protein structure datasets by providing: (1) storage-efficient dataloaders for large-scale structural databases including AlphaFoldDB and ESM Atlas, as well as (2) utilities for constructing new tasks from the entire PDB. ProteinWorkshop is available at: github.com/a-r-j/ProteinWorkshop.},
  preview =      {ProteinWorkshop.png},
  abbr =         {ICLR},
}

@inproceedings{morehead2024posebench,
  title =        {Deep Learning for Protein-Ligand Docking: Are We There Yet?},
  author =       {Morehead, Alex and Giri, Nabin and Liu, Jian and Cheng,
                  Jianlin},
  booktitle =    {ICML AI4Science Workshop},
  year =         2024,
  note =         {Selected as a spotlight presentation (top 20% - 30/159)},
  selected =     true,
  google_scholar_id={IWHjjKOFINEC},
  html =          {https://arxiv.org/abs/2405.14108},
  abstract =     {The effects of ligand binding on protein structures and their in vivo functions carry numerous implications for modern biomedical research and biotechnology development efforts such as drug discovery. Although several deep learning (DL) methods and benchmarks designed for protein-ligand docking have recently been introduced, to date no prior works have systematically studied the behavior of docking methods within the practical context of (1) predicted (apo) protein structures, (2) multiple ligands concurrently binding to a given target protein, and (3) having no prior knowledge of binding pockets. To enable a deeper understanding of docking methods' real-world utility, we introduce PoseBench, the first comprehensive benchmark for practical protein-ligand docking. PoseBench enables researchers to rigorously and systematically evaluate DL docking methods for apo-to-holo protein-ligand docking and protein-ligand structure generation using both single and multi-ligand benchmark datasets, the latter of which we introduce for the first time to the DL community. Empirically, using PoseBench, we find that all recent DL docking methods but one fail to generalize to multi-ligand protein targets and also that template-based docking algorithms perform equally well or better for multi-ligand docking as recent single-ligand DL docking methods, suggesting areas of improvement for future work. Code, data, tutorials, and benchmark results are available at https://github.com/BioinfoMachineLearning/PoseBench.},
  preview =      {PoseBench.png},
  abbr =         {ICML AI4Sci},
}

@inproceedings{anand2024rna,
  title =        {RNA-FrameFlow for de novo 3D RNA Backbone Design},
  author =       {Anand*, Rishabh and Joshi*, Chaitanya K and Morehead, Alex and
                  Jamasb, Arian R and Harris, Charles and Matthis, Simon V and
                  Didi, Kieran and Hooi, Bryan, and Li{\`o}, Pietro},
  booktitle =    {ICML AI4Science \& SPIGM Workshops},
  year =         2024,
  selected =     true,
  note =         {Selected as a SPIGM (AI4Science) oral (spotlight) presentation},
  google_scholar_id={qUcmZB5y_30C},
  html =          {https://arxiv.org/abs/2406.13839},
  abstract =     {We introduce RNA-FrameFlow, the first generative model for 3D RNA backbone design. We build upon SE(3) flow matching for protein backbone generation and establish protocols for data preparation and evaluation to address unique challenges posed by RNA modeling. We formulate RNA structures as a set of rigid-body frames and associated loss functions which account for larger, more conformationally flexible RNA backbones (13 atoms per nucleotide) vs. proteins (4 atoms per residue). Toward tackling the lack of diversity in 3D RNA datasets, we explore training with structural clustering and cropping augmentations. Additionally, we define a suite of evaluation metrics to measure whether the generated RNA structures are globally self-consistent (via inverse folding followed by forward folding) and locally recover RNA-specific structural descriptors. The most performant version of RNA-FrameFlow generates locally realistic RNA backbones of 40-150 nucleotides, over 40% of which pass our validity criteria as measured by a self-consistency TM-score >= 0.45, at which two RNAs have the same global fold. Open-source code: https://github.com/rish-16/rna-backbone-design},
  preview =      {RNA-FrameFlow.png},
  abbr =         {ICML AI4Sci & SPIGM},
}

% 2025 papers:
@inproceedings{joshi2025grnade,
  title={g{RNA}de: Geometric Deep Learning for 3D {RNA} inverse design},
  author={Joshi, Chaitanya K and Jamasb, Arian R and Vi{\~n}as, Ramon
          and Harris, Charles and Mathis, Simon V and Morehead, Alex and
          Anand, Rishabh and Li{\`o}, Pietro},
  booktitle={The Thirteenth International Conference on Learning
            Representations (ICLR)},
  year={2025},
  note={Also presented at the ICML 2023 CompBio workshop},
  google_scholar_id={dhFuZR0502QC},
  html={https://openreview.net/forum?id=lvw3UgeVxS},
  abstract={Computational RNA design tasks are often posed as inverse problems, where sequences are designed based on adopting a single desired secondary structure without considering 3D conformational diversity. We introduce gRNAde, a geometric RNA design pipeline operating on 3D RNA backbones to design sequences that explicitly account for structure and dynamics. gRNAde uses a multi-state Graph Neural Network and autoregressive decoding to generates candidate RNA sequences conditioned on one or more 3D backbone structures where the identities of the bases are unknown. On a single-state fixed backbone re-design benchmark of 14 RNA structures from the PDB identified by Das et al. (2010), gRNAde obtains higher native sequence recovery rates (56% on average) compared to Rosetta (45% on average), taking under a second to produce designs compared to the reported hours for Rosetta. We further demonstrate the utility of gRNAde on a new benchmark of multi-state design for structurally flexible RNAs, as well as zero-shot ranking of mutational fitness landscapes in a retrospective analysis of a recent ribozyme. Experimental wet lab validation on 10 different structured RNA backbones finds that gRNAde has a success rate of 50% at designing pseudoknotted RNA structures, a significant advance over 35% for Rosetta. Open source code and tutorials are available at: github.com/chaitjo/geometric-rna-design.},
  preview={gRNAde.png},
  abbr={ICLR},
}

@inproceedings{morehead2025flowdock,
      title={FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction}, 
      author={Alex Morehead and Jianlin Cheng},
      booktitle={Intelligent Systems for Molecular Biology (ISMB)},
      year=2025,
      note = {Presented as a CASP16 top-5 method},
      selected = true,
      google_scholar_id={hFOr9nPyWt4C},
      html={https://arxiv.org/abs/2412.10966},
      abstract = {Powerful generative models of protein-ligand structure have recently been proposed, but few of these methods support both flexible protein-ligand docking and affinity estimation. Of those that do, none can directly model multiple binding ligands concurrently or have been rigorously benchmarked on pharmacologically relevant drug targets, hindering their widespread adoption in drug discovery efforts. In this work, we propose FlowDock, a deep geometric generative model based on conditional flow matching that learns to directly map unbound (apo) structures to their bound (holo) counterparts for an arbitrary number of binding ligands. Furthermore, FlowDock provides predicted structural confidence scores and binding affinity values with each of its generated protein-ligand complex structures, enabling fast virtual screening of new (multi-ligand) drug targets. For the commonly-used PoseBusters Benchmark dataset, FlowDock achieves a 51% blind docking success rate using unbound (apo) protein input structures and without any information derived from multiple sequence alignments, and for the challenging new DockGen-E dataset, FlowDock matches the performance of single-sequence Chai-1 for binding pocket generalization. Additionally, in the ligand category of the 16th community-wide Critical Assessment of Techniques for Structure Prediction (CASP16), FlowDock ranked among the top-5 methods for pharmacological binding affinity estimation across 140 protein-ligand complexes, demonstrating the efficacy of its learned representations in virtual screening. Source code, data, and pre-trained models are available at https://github.com/BioinfoMachineLearning/FlowDock.},
      preview = {FlowDock.gif},
      abbr = {ISMB},
}

@article{morehead2025multicom,
  title =        {Protein-ligand structure and affinity prediction in CASP16
                  using a geometric deep learning ensemble and flow matching},
  author =       {Morehead, Alex and Liu, Jian and Neupane, Pawan and
                  Giri, Nabin, and Cheng, Jianlin},
  journal =      {Proteins: Structure, Function, and Bioinformatics},
  year =         2025,
  note =         {Presented as a CASP16 top-5 method},
  google_scholar_id={mB3voiENLucC},
  html =         {https://www.authorea.com/doi/full/10.22541/au.173812699.96369139},
  abstract={Predicting the structure of ligands bound to proteins is a foundational problem in modern biotechnology and drug discovery, yet little is known about how to combine the predictions of protein-ligand structure (poses) produced by the latest deep learning methods to identify the best poses and how to accurately estimate the binding affinity between a protein target and a list of ligand candidates. Further, a blind benchmarking and assessment of protein-ligand structure and binding affinity prediction is necessary to ensure it generalizes well to new settings. Towards this end, we introduce MULTICOM_ligand, a deep learning-based protein-ligand structure and binding affinity prediction ensemble featuring structural consensus ranking for unsupervised pose ranking and a new deep generative flow matching model for joint structure and binding affinity prediction. Notably, MULTICOM_ligand ranked among the top-5 ligand prediction methods in both protein-ligand structure prediction and binding affinity prediction in the 16th Critical Assessment of Techniques for Structure Prediction (CASP16), demonstrating its efficacy and utility for real-world drug discovery efforts. The source code for MULTICOM_ligand is freely available on GitHub.},
  preview =      {MULTICOM_ligand.png},
  abbr =         {Proteins},
}
